{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d35c06ce-d8f2-4f82-92a7-9c7b7a23ce68",
   "metadata": {},
   "source": [
    "## 介绍\n",
    "这个是`chinese-gpt2`的推理代码\n",
    "1. 将`model_name_or_path = \"checkpoint-36000\"`里面的`\"checkpoint-36000\"`,修改为模型所在的路径。\n",
    "2. 然后运行下面一个代码块，即可输出文本生成结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2245e96c-813e-421e-abd1-eadeb09060fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/nlp_train/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AutoTokenizer\n",
    "\n",
    "# 加载训练好的模型\n",
    "model_name_or_path = \"checkpoint-42000\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "\n",
    "# add the EOS token as PAD token to avoid warnings\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name_or_path, pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b538a451-b169-48d3-9110-6adc1bd99e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "你 是 谁 的 错 ？ 我 不 知 道 该 怎 么 面 对 这 个 世 界 ， 我 只 是 一 个 普 普 通 通 的 人 。 我, 简 单 的 描 述 是 我 的 真 实 情 况 是 这 样 的 ： 我 和 我 女 朋 友 在 一 起 快 两 年 了 ， 但 是 她 对 我 很 好 ， 所 以 我 们 之 间 的 感 情 一 直 都 比 较 好 。 可 是 后 来 我 发 现 ， 她 的 脾 气 越 来 越 大 ， 而 且 她 也 不 喜 欢 我 ， 因 为 她 是 个 很 内 向 的 女 孩 子 ， 不 爱 和 别 人 说 话 。 她 说 她 很 爱 我 。 而 我 却 不 是 那 种 特 别 内 敛 的 男 生 ， 和 她 相 处 的 时 间 也 很 少 ， 甚 至 有 时 候 她 会 说 一 些 很 难 听 的 话 ， 让 我 觉 得 很 不 舒 服 。 其 实 我 真 的 很\n"
     ]
    }
   ],
   "source": [
    "txt = \"\"\"\\\n",
    "你是谁\n",
    "\"\"\"\n",
    "# encode context the generation is conditioned on\n",
    "input_ids = tokenizer.encode(txt, return_tensors='pt', add_special_tokens=False)\n",
    "# set no_repeat_ngram_size to 2\n",
    "beam_output = model.generate(\n",
    "    input_ids, \n",
    "    max_length=200, \n",
    "    num_beams=5, \n",
    "    no_repeat_ngram_size=2, \n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(beam_output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e83c8df-6477-4e5c-be5b-772ae71f990d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
