问题,回答,所属分类
计算机网络五层模型入门,"天各一方的两台计算机是如何通信的呢？在成千上万的计算机中，为什么一台计算机能够准确着寻找到另外一台计算机，并且把数据发送给它呢？
可能很多人都听说过网络通信的 5 层模型，但是可能并不是很清楚为什么需要五层模型，五层模型负责的任务也有可能经常混淆。下面是网络通信的五层模型

说实话，五层模型的具体内容还是极其复杂的，不过今天这篇文章，我将用最简洁的模式，通过网络通信的五层模型来讲解一台计算机是如何找到另外一台计算机并且把数据发送给另一台计算机的，就算你没学过计算机网络，也能够听的懂。
一台计算机与另一台计算机要进行通信，第一件要做的事是什么？当然是要把这台计算机与另外的其他计算机连起来啊，这样，我们才能把数据传输过去。例如可以通过光纤啊，电缆啊，双绞线啊等介质把他们连接起来，然后才能进行通信。

也就是说，物理层负责把两台计算机连起来，然后在计算机之间通过高低电频来传送0,1这样的电信号。
前面说了，物理层它只是单纯着负责把计算机连接起来，并且在计算机之间传输0，1这样的电信号。如果这些0，1组合的传送毫无规则的话，计算机是解读不了的。一大堆0，1谁知道是什么鬼啊。

因此，我们需要制定一套规则来进行0，1的传送。例如多少个电信号为一组啊，每一组信号应该如何标识才能让计算机读懂啊等等。
于是，有了以太网协议。
1. 以太网协议
以太网协议规定，一组电信号构成一个数据包，我们把这个数据包称之为帧。每一个桢由标头(Head)和数据(Data)两部分组成。

帧的大小一般为 64 – 1518 个字节。假如需要传送的数据很大的话，就分成多个桢来进行传送。
对于表头和数据这两个部分，他们存放的都是一些什么数据呢？我猜你眯着眼睛都能想到他们应该放什么数据。    毫无疑问，我们至少得知道这个桢是谁发送，发送给谁的等这些信息吧？所以标头部分主要是一些说明数据，例如发送者，接收者等信息。而数据部分则是这个数据包具体的，想给接守者的内容。
大家想一个问题，一个桢的长度是 64~1518 个字节，也就是说桢的长度不是固定的，那你觉得标头部分的字节长度是固定的吗？它当然是固定的啊，假如不是固定的，每个桢都是单独发的，那计算机怎么知道标头是几个字节，数据是几个字节呢。所以标头部分的字节是固定的，并且固定为18个字节。
把一台计算的的数据通过物理层和链路层发送给另一台计算机，究竟是谁发给谁的，计算机与计算机之间如何区分，，你总得给他们一个唯一的标识吧？
于是，MAC 地址出现了。
2. MAC 地址
连入网络的每一个计算机都会有网卡接口，每一个网卡都会有一个唯一的地址，这个地址就叫做 MAC 地址。计算机之间的数据传送，就是通过 MAC 地址来唯一寻找、传送的。

MAC地址 由 48 个二进制位所构成，在网卡生产时就被唯一标识了。
3. 广播与ARP协议
(1). 广播

如图，假如计算机 A 知道了计算机 B 的 MAC 地址，然后计算机 A 想要给计算机 B 传送数据，虽然计算机 A 知道了计算机 B 的 MAC 地址，可是它要怎么给它传送数据呢？计算机 A 不仅连着计算机 B，而且计算机 A 也还连着其他的计算机。    虽然计算机 A 知道计算机 B 的 MAC 地址，可是计算机 A 却不知道知道计算机 B 是分布在哪边路线上，为了解决这个问题，于是，有了广播的出现。
在同一个子网中，计算机 A 要向计算机 B 发送一个数据包，这个数据包会包含接收者的 MAC 地址。当发送时，计算机 A 是通过广播的方式发送的，这时同一个子网中的计算机 C, D 也会收到这个数据包的，然后收到这个数据包的计算机，会把数据包的 MAC 地址取出来，与自身的 MAC 地址对比，如果两者相同，则接受这个数据包，否则就丢弃这个数据包。这种发送方式我们称之为广播,就像我们平时在广场上通过广播的形式呼叫某个人一样，如果这个名字是你，你就理会一下，如果不是你，你就当作听不见。
(2). ARP 协议。
那么问题来了，计算机 A 是如何知道计算机 B 的 MAC 地址的呢？这个时候就得由 ARP 协议这个家伙来解决了，不过 ARP 协议会涉及到IP地址，我们下面才会扯到IP地址。因此我们先放着，就当作是有这么一个 ARP 协议，通过它我们可以知道子网中其他计算机的 MAC 地址。
上面我们有说到子网这个关键词，实际上我们所处的网络，是由无数个子网络构成的。广播的时候，也只有同一个子网里面的计算机能够收到。
假如没有子网这种划分的话，计算机 A 通过广播的方式发一个数据包给计算机 B , 其他所有计算机也都能收到这个数据包，然后进行对比再舍弃。世界上有那么多它计算机，每一台计算机都能收到其他所有计算机的数据包，那就不得了了。那还不得奔溃。  因此产生了子网这么一个东西。
那么问题来了，我们如何区分哪些 MAC 地址是属于同一个子网的呢？假如是同一个子网，那我们就用广播的形式把数据传送给对方，如果不是同一个子网的，我们就会把数据发给网关，让网关进行转发。
为了解决这个问题，于是，有了 IP 协议。
1. IP协议
IP协议，它所定义的地址，我们称之为IP地址。IP协议有两种版本，一种是 IPv4,另一种是 IPv6。不过我们目前大多数用的还是 IPv4，我们现在也只讨论 IPv4 这个版本的协议。
这个 IP 地址由 32 位的二进制数组成，我们一般把它分成4段的十进制表示，地址范围为0.0.0.0~255.255.255.255。
每一台想要联网的计算机都会有一个IP地址。这个IP地址被分为两部分，前面一部分代表网络部分，后面一部分代表主机部分。并且网络部分和主机部分所占用的二进制位数是不固定的。
假如两台计算机的网络部分是一模一样的，我们就说这两台计算机是处于同一个子网中。例如 192.168.43.1 和 192.168.43.2, 假如这两个 IP 地址的网络部分为 24 位，主机部分为 8 位。那么他们的网络部分都为 192.168.43，所以他们处于同一个子网中。
可是问题来了，你怎么知道网络部分是占几位，主机部分又是占几位呢？也就是说，单单从两台计算机的IP地址，我们是无法判断他们的是否处于同一个子网中的。
这就引申出了另一个关键词————子网掩码。子网掩码和IP地址一样也是 32 位二进制数，不过它的网络部分规定全部为 1，主机部分规定全部为 0.也就是说，假如上面那两个IP地址的网络部分为 24 位，主机部分为 8 位的话，那他们的子网掩码都为 11111111.11111111.11111111.00000000，即255.255.255.0。

那有了子网掩码，如何来判端IP地址是否处于同一个子网中呢。显然，知道了子网掩码，相当于我们知道了网络部分是几位，主机部分是几位。我们只需要把 IP 地址与它的子网掩码做与(and)运算，然后把各自的结果进行比较就行了，如果比较的结果相同，则代表是同一个子网，否则不是同一个子网。
例如，192.168.43.1和192.168.43.2的子码掩码都为255.255.255.0，把IP与子码掩码相与，可以得到他们都为192.168.43.0，进而他们处于同一个子网中。
2. ARP协议
有了上面IP协议的知识，我们回来讲一下ARP协议。
有了两台计算机的IP地址与子网掩码，我们就可以判断出它们是否处于同一个子网之中了。
假如他们处于同一个子网之中，计算机A要给计算机B发送数据时。我们可以通过ARP协议来得到计算机B的MAC地址。
ARP协议也是通过广播的形式给同一个子网中的每台电脑发送一个数据包(当然，这个数据包会包含接收方的IP地址)。对方收到这个数据包之后，会取出IP地址与自身的对比，如果相同，则把自己的MAC地址回复给对方，否则就丢弃这个数据包。这样，计算机A就能知道计算机B的MAC地址了。

可能有人会问，知道了MAC地址之后，发送数据是通过广播的形式发送，询问对方的MAC地址也是通过广播的形式来发送，那其他计算机怎么知道你是要传送数据还是要询问MAC地址呢？其实在询问MAC地址的数据包中，在对方的MAC地址这一栏中，填的是一个特殊的MAC地址，其他计算机看到这个特殊的MAC地址之后，就能知道广播想干嘛了。
假如两台计算机的IP不是处于同一个子网之中，这个时候，我们就会把数据包发送给网关，然后让网关让我们进行转发传送
3. DNS服务器
这里再说一个问题，我们是如何知道对方计算机的IP地址的呢？这个问题可能有人会觉得很白痴，心想，当然是计算机的操作者来进行输入了。这没错，当我们想要访问某个网站的时候，我们可以输入IP来进行访问，但是我相信绝大多数人是输入一个网址域名的，例如访问百度是输入 www.baidu.com 这个域名。其实当我们输入这个域名时，会有一个叫做DNS服务器的家伙来帮我们解析这个域名，然后返回这个域名对应的IP给我们的。
因此，网络层的功能就是让我们在茫茫人海中，能够找到另一台计算机在哪里，是否属于同一个子网等。
通过物理层、数据链路层以及网络层的互相帮助，我们已经把数据成功从计算机A传送到计算机B了，可是，计算机B里面有各种各样的应用程序，计算机该如何知道这些数据是给谁的呢？
这个时候，端口(Port)这个家伙就上场了，也就是说，我们在从计算机A传数据给计算表B的时候，还得指定一个端口，以供特定的应用程序来接受处理。
也就是说，传输层的功能就是建立端口到端口的通信。相比网络层的功能是建立主机到主机的通信。
也就是说，只有有了IP和端口，我们才能进行准确着通信。这个时候可能有人会说，我输入IP地址的时候并没有指定一个端口啊。其实呢，对于有些传输协议，已经有设定了一些默认端口了。例如http的传输默认端口是80，这些端口信息也会包含在数据包里的。
传输层最常见的两大协议是 TCP 协议和 UDP 协议，其中 TCP 协议与 UDP 最大的不同就是 TCP 提供可靠的传输，而 UDP 提供的是不可靠传输。
终于说到应用层了，应用层这一层最接近我们用户了。
虽然我们收到了传输层传来的数据，可是这些传过来的数据五花八门，有html格式的，有mp4格式的，各种各样。你确定你能看的懂？
因此我们需要指定这些数据的格式规则，收到后才好解读渲染。例如我们最常见的 Http 数据包中，就会指定该数据包是 什么格式的文件了。
五层模型至此讲到这里。对于有些层讲的比较简洁，就随便概况了一下。因为如果我说的详细一点的话，篇幅肯定会特别特别长，我着已经是尽最大的努力以最简洁的方式来讲的了。如果你想详细去了解，可以去买计算机网络相应的资料，强烈推荐《计算机网络：自顶向下》这本书。希望我的讲解能让你对计算机之间数据的传输有个大概的了解。
计算机网络",
通信双方如何保证消息不丢失？,"小白：你知道吗？数据在传输的时候是分割成一小块一小块传输的，我们把这一小块的数据称之为一个分组。我们在传输这块分组的时候，主要面临两个问题。
1、这个分组在传输的过程中，由于在信道传输过程中，收到干扰，导致这个分组到达目的地之后出现了差错，例如分组里面的二进制位1变成了0，0变成了1。
2、分组还没传输到目的地，就丢失了，我们也把这种情况称之为丢包。
接下来我们先来谈谈第一种情况吧，即分组传到目的地之后出现了差错。
这里我们先假设计算机A给计算机B发送分组数据





一禅：如果没有差错的话，计算机B就给计算机A发送一个ACK分组，告诉对方，数据正确无误。如果出现差错的话，就给对方发送一个NAK分组，告诉对方，分组数据出现了差错。
当计算机A收到接受方的反馈之后，如果收到的是ACK分组，那么就继续发送下一个分组数据。如果收到的是NAK分组，那么就重新传输这个分组。





小白：这时就会出现了混乱，就相当于两个人A,B在对话。
A : 传输给你一个分组
B :你发的是啥，可以重发一次吗？
A :你发的又是啥？可以重发一次吗？
B :你发的又是啥？可以重发一次吗
……
进去无限混乱之中



小白：法子倒是不错，不过如果分组出现大量差错，会让校验码变的很难设计的,而且校验码属于与正文内容无关的数据，占了太多比特位的话，会降低传输效率。还有其他法子吗？




小白：我们可以给每个分组添加一个序号啊，这样就可以知道是重传的分组还是新的分组了。
如果B收到的分组没出差错，这时又收到一个序号相同的分组，这时B就知道这个分组是属于重传的分组了，这时B就把这个重传的分组丢弃。


一禅：哈哈，我知道怎么解决，可以采取和分组差错类似的方法，如果A迟迟没有收到B的反馈，A就可以认为这个分组丢失了，重新发送。
所以我们每次发送分组的时候，需要给该分组设置一个定时器

小白：脑子转的挺快啊。不过你知道吗？我们上面谈的那些，都是A发送一个分组，收到B的反馈之后，再发送下一个分组。你不觉得这种方法很浪费信道的资源吗？






  这里先说明一下，如果同时发送多个分组时，最需要处理的问题就是接受方收到分组时，并非按照顺序收到分组的，有可能序号小的分组先达到，这时就会出现了乱序。

在回退N步法中允许发送多个分组而不需要等待确认，但它也受限于在流水线中未确认的分组数不能超过某个最大允许数N。如下图，我们将基序号定义为最早的未确认分组的序号，将下一个序号(nextseqnum)定义为最小的未使用序号(即下一个待发送分组)。

此时我们可以将序号分成4段。在[0, base-1]段内的序号对应已发送并且已经确认的分组序号，[base,nextseqnum]段内对应已经发送但未确认的分组序号，[nextseqnum, base+N-1]段内表示即将要被发送的分组序号。而那些大于base+N的序号目前还不能使用，直到当前流水线中未被确认的分组得到确认，窗口整体向右移动之后，才能够被使用。
所以，我们常把N称之为窗口长度，由于窗口在序号范围内移动，也被GBN协议称之为滑动窗口协议。
对于GBN协议，计算机A(发送方)需要响应以下两个事件：
1、收到一个ACK：在GBN协议中，对序号为n的分组的确认采取累计确认的方式。也就是说，当A收到序号为n的分组时，表明分组n以及n之前的分组已经被B正确接受了。
2、超时事件： 当久久没有收到ACK时，A就认为它发送的分组已经丢失了，这时A会重传所有已发送但还未被确认的分组。这个时候需要注意的是，并不是为每个分组设置一个定时器，而是在序号[base,nextseqnum-1]中，设置一个定时器，当base发送的那一刻，就开始计时，当收到一个ACK时，则刷新重新开始计时。
计算机B(接收方)则需要处理一下事件：
如果一个序号为n的分组被正确收到，并且按序(所谓按序就是指n-1的分组也已经收到了)，则B为分组n发送一个ACK，否则，丢弃该分组，并且为最近按序接收的分组重新发送ACK。
接收方的这种处理方式，意味着如果n被正确交付，则意味着比n小的所有分组也被正确交付了。






小白：你这个想法其实也是挺不错的，不过如果分组n-1丢失了，那么按照GBN的重传规则，这时n-1和n都会被重传，这时之前缓存的n就没啥用了。而且，我们如果把n丢弃了，那么我们就不需要缓存任何失序的分组了，这样可以让我们的设计更加简单哦。
回退N步协议的缺点也是很明显的，单个分组的差错能够引起GBN重传大量的分组，而且许多分组根本就没有必要重传。例如我们发送的序号为0-100，万一序号为1的分组出现了某些差错，这会导致1-100的分组会被重传，想想这是多么恐怖的事情啊。
因此，出现了选择重传这种协议。所谓“选择”，也就是有选择着去重传。
不过选择重传和回退N步是很相似的，只是在选择重传中，接收方收到失序的分组时，会把它缓存起来，直到拼凑到分组按序，才把分组传输给上一层。而发送方会为每个分组设置一个定时器，这样，只需要重传那些没有被接收方正确接收的分组就可以了。
我来个例子吧。
假设窗口长度N=6，这时A向B发送分组1-5。

当A收到序号为3的ACK，则状态如下：

注意，这个时候虽然序号3被确认接收了，但窗口并不能向右移动一格。
接下来受到序号为1的ACK，则：

这个时候窗口才可以向右移动一格。注意，黄色的那些序号是可以继续发送分组的，只是我没有继续填充发送而已。
接着收到序号为2的分组。

这个时候窗口向右移动了两个格。
接着继续这样接收下去，如果还有分组没发送的，就从nextseqnum开始填充发送…
如果某个分组超时了，就重新传输这个分组。
对于接收方B的窗口来说也差不多也一样，在此不展开。接收方对于失序的分组缓存起来，直到所有丢失的分组全部被收到为止，再把这批分组按序交付给上一层。
我在书上截了张完整的例子图：






  这样，两个完全陌生的计算机就可以就行可靠数据传输了。这也是可靠数据传输的原理。


计算机网络",
集线器、交换机与路由器有什么区别？,"注：本文旨在简单的说明集线器、交换机与路由器的区别，因而忽略了很多细节。三者实际的发展过程和工作原理并非文中所写的这么简单。如果你看完本文能大概了解到三者的异同，本文的目的就达到了。至于更具体的技术问题，欢迎在留言中探讨。

我相信我们都玩过一款特别火的游戏：帝国时代。小时候想要玩帝国时代，需要到软件城购买盗版光盘安装（大概3块钱一张左右的样子，当时已经觉得很便宜了，谁想到现在有了网络之后是免费）。下载完成后只能进行单机模式。
小A是一个帝国时代大神，他打通了游戏的所有关卡，可以一个人单挑8个疯狂的电脑。渐渐他觉得无聊了，想要找小伙伴一起PK。
但是如何实现两台设备的互联呢？小A很聪明，他发明了一个类似于USB口一样的可以传输数据的端口，他将其命名为网口。小A通过一根网线将自己的电脑与小B的网口相连，实现了两台电脑间的互连。

两个小伙伴很开心，联机玩了起来，这时被路过的小C看见了，小C也要加入进来。但是我们知道，每台电脑只有一个网口，无法实现三台电脑的相互连接，那要要怎么办呢？

这时候小B出了一个主意：咱们再找一台计算机，给他多设计几个网口，我们每个人都连到这台计算机的网口上，不也实现咱们哥几个之间的互连了吗。
说干就干，于是他们设计出了一款微型计算机，他本身具备多个网口，专门实现多台计算机的互联作用，这个微型计算机就是集线器（HUB）。顾名思义，集线器起到了一个将网线集结起来的作用，实现最初级的网络互通。集线器是通过网线直接传送数据的，我们说他工作在物理层。
有了集线器后，越来越多的小伙伴加入到游戏中，小D、小E等人都慕名而来。然而集线器有一个问题，由于和每台设备相连，他不能分辨出具体信息是发送给谁的，只能广泛的广播出去。
例如小A本来想问小C：你吃了吗？结果小B，小D和小E等所有连接在集线器上的用户都收到了这一信息，且由于处于同一网络，小A说话时其他人不能发言，否则信息间会产生碰撞，引发错误，我们叫做各设备处于同一冲突域内。


这样的设备用户体验极差，于是小伙伴们一起讨论改进措施。这时聪明的小D发话了：我们给这台设备加入一个指令，让他可以根据网口名称自动寻址传输数据。
比如我把小A的网口命名为macA，将小C的命名为macC，这时如果小A想要将数据传给小C，则设备会根据网口名称macA和macC自动将资料从A的电脑传送到C的电脑中，而不让小B、小D和小E收到。
也就是说，这台设备解决了冲突的问题，实现了任意两台电脑间的互联，大大地提升了网络间的传输速度，我们把它叫做交换机。由于交换机是根据网口地址传送信息，比网线直接传送多了一个步骤，我们也说交换机工作在数据链路层。


这回小伙伴们高兴了，他们愉快地玩耍起来。渐渐地，他们在当地有了名气，吸引了越来越多的小伙伴加入到他们的队伍中。直到有一天，一个外村的小伙突然找上门来，希望能和他们一起互联，实现跨村间的网络对战。
小A说可以呀，于是他们找了一根超长的网线将两个村落的交换机连在了一起。结果发现一件奇怪的事：两个村落间竟然不能相互通信。怎么着，原来那边的电脑和他们用的不是一套操作系统，这导致信息间的传送形式的不匹配。在这期间，还有其他村落的人也来找过小A，可是小A发现，每个村子之间用的操作系统都不一样。
这可咋办呐？难道以后只能各自村子玩各自的了吗？为了解决这一问题，各村的小伙伴们坐在一起组织了一场会议，最终得出了一套解决方案：采用同样的信息传送形式（像不像秦始皇统一度量衡）。
那如何实现呢？小伙伴们规定，不同的村子间先在各自的操作系统上加上一套相同的协议。不同村落通信时，信息经协议加工成统一形式，再经由一个特殊的设备传送出去。这个设备就叫做路由器。路由器通过IP地址寻址，我们说它工作在计算机的网络层。
这样，经由如此的一系列改装，小A终于带领村民们实现了整个乡镇的通信。随着越来越多的城里人也加入小A的协议，小A带领村民逐步实现了全市、全国乃至全世界的通信。这一套协议便是TCP/IP协议簇，互联网也便这样形成了。

然而，即便如今全网络已遍布了全世界，在小A和村里的小伙伴对战帝国时代的时候，也仍然用着交换机。只有和外面更大的世界交流的时候才用到路由器。
总结：交换机适合局域网内互联，路由器实现全网段互联。
计算机网络",
什么是 TCP 拥塞控制？,"大家可能都听说过拥塞控制和流量控制，想必也有一些人可能还分不清拥塞控制和流量控制，进而把他们当作一回事。拥塞控制和流量控制虽然采取的动作很相似，但拥塞控制与网络的拥堵情况相关联，而流量控制与接收方的缓存状态相关联。
也就是说，拥塞控制和流量控制是针对完全不同的问题而采取的措施。今天这篇文章，我们先来讲讲拥塞控制。
为了方便，我们假设主机 A 给主机 B 传输数据。
我们知道，两台主机在传输数据包的时候，如果发送方迟迟没有收到接收方反馈的 ACK，那么发送方就会认为它发送的数据包丢失了，进而会重新传输这个丢失的数据包。
然而实际情况有可能此时有太多主机正在使用信道资源，导致网络拥塞了，而 A 发送的数据包被堵在了半路，迟迟没有到达 B。这个时候 A 就会误认为是发生了丢包情况，进而重新传输这个数据包。
结果就是不仅浪费了信道资源，还会使网络更加拥塞。因此，我们需要进行拥塞控制。
A 与 B 通过三次握手建立连接之后，就可以向 B 发送数据了，然而这个时候 A 并不知道此时的网络拥塞情况如何，也就是说，A 不知道一次性连续发送多少个数据包比较合适，我们也把 A 一次性连续发送多少个数据包称之为拥塞窗口，用 N 代表此时拥塞窗口的大小吧。
为了探测网络的拥塞情况，我们可以采取以下两种策略：
1、先发送一个数据包试探下，如果该数据包没有发生超时事件(也就是没有丢包)。那么下次发送时就发送2个，如果还是没有发生超时事件，下次就发送3个，以此类推，即N = 1, 2, 3, 4, 5…..

2、一个一个增加实在是太慢了，所以可以刚开始发送1个，如果没有发生超时时间，就发送2个，如果还是没有发送超时事件就发送4个，接着8个…，用翻倍的速度类推,即 N = 1, 2, 4, 8, 16…

无论是第一种方法还是第二种方法，最后都会出现瓶颈值。不过这里值得注意的是，第一种情况的增长速率确实有点慢，但是第二种情况以指数增长，增长速度有点太快了，可能一下子就到瓶颈值了。
为了解决这个过慢或过快的问题，我们可以把第一种方法和第二种方法结合起来。也就是说，我们刚开始可以以指数的速度增长，增长到某一个值，我们把这个值称之为阈值吧，用变量 ssthresh 代替。当增长到阈值时，我们就不在以指数增长了，而是一个一个线性增长。
所以最终的策略是：前期指数增长，到达阈值之后，就以一个一个线性的速度来增长。

(注：8之后其实是直线的，那里只是弯曲了一下)
我们也把指数增长阶段称之为慢启动，线性增长阶段称之为拥塞避免
无论是指数增长还是一个一个增长，最终肯定会出现超时事件，总不可能无限增长吧。当出现超时事件时，我们就认为此时网络出现了拥塞了，不能再继续增长了。我们就把这个时候的N的值称之为瓶颈值吧，用MAX 这个字母来代替吧，即最大值。

注：这里再次提醒阈值过后是一个一个线性增长，图中之所以弯曲是因为我画图原因导致的
当达到最大值MAX之后，我们该怎么办呢？
当到达最大值之后我们采取的策略是这样的：
我们就回到最初的最初的状态，也就是说从1，2，4，8…..开始,不过这个时候我们还会把ssthresh调小，调为MAX值的一半，即ssthresh = MAX / 2。

图中阈值为8，瓶颈值是14；超时事件发生后，阈值为14 / 2 = 7。
超时事件发送就一定是网络出现了拥堵吗？其实也有可能不是出现了网络拥堵，有可能是因为某个数据包出现了丢失或者损害了，导致了这个数据包超时事件发生了
为了防止这种情况，我们是通过冗余 ACK来处理的。我们都知道，数据包是有序号的，如果A给B发送M1, M2, M3, M4, M5…N个数据包，如果B收到了M1, M2, M4….却始终没有收到M3，这个时候就会重复确认M2，意在告诉A,M3还没收到，可能是丢失

当A连续收到了三个确认M2的ACK，且M3超时事件还没发生。A就知道M3可能丢失了，这个时候A就不必等待M3设置的计时器到期了，而是快速重传M3。并且把ssthresh设置为MAX的一半，即ssthresh = MAX/2，但是这个时候并非把控制窗口N设置为1，而是让N = ssthresh，N在一个一个增长。

我们也把这种情况称之为快速恢复。而这种具有快速恢复的TCP版本称之为TCP Reno。
还有另外一种TCP版本，无论是收到三个相同的ACK还是发生超时事件，都把拥塞窗口的大小设为1，从最初状态开始，这种版本的TCP我们称之为TCP Tahoe。
计算机网络",
什么是 TCP 流量控制,"双方在通信的时候，发送方的速率与接收方的速率是不一定相等，如果发送方的发送速率太快，会导致接收方处理不过来，这时候接收方只能把处理不过来的数据存在缓存区里（失序的数据包也会被存放在缓存区里）。
如果缓存区满了发送方还在疯狂着发送数据，接收方只能把收到的数据包丢掉，大量的丢包会极大着浪费网络资源，因此，我们需要控制发送方的发送速率，让接收方与发送方处于一种动态平衡才好。
对发送方发送速率的控制，我们称之为流量控制。

接收方每次收到数据包，可以在发送确定报文的时候，同时告诉发送方自己的缓存区还剩余多少是空闲的，我们也把缓存区的剩余大小称之为接收窗口大小，用变量 win 来表示接收窗口的大小。
发送方收到之后，便会调整自己的发送速率，也就是调整自己发送窗口的大小，当发送方收到接收窗口的大小为0时，发送方就会停止发送数据，防止出现大量丢包情况的发生。

当发送方停止发送数据后，该怎样才能知道自己可以继续发送数据？
我们可以采用这样的策略：当接收方处理好数据，接受窗口 win > 0 时，接收方发个*通知报文*去通知发送方，告诉他可以继续发送数据了。当发送方收到窗口大于0的报文时，就继续发送数据。
不过这时候可能会遇到一个问题，假如接收方发送的通知报文，由于某种网络原因，这个报文丢失了，这时候就会引发一个问题：接收方发了通知报文后，继续等待发送方发送数据，而发送方则在等待接收方的通知报文，此时双方会陷入一种僵局。
为了解决这种问题，我们采用了另外一种策略：当发送方收到接受窗口 win = 0 时，这时发送方停止发送报文，并且同时开启一个定时器，每隔一段时间就发个测试报文去询问接收方，打听是否可以继续发送数据了，如果可以，接收方就告诉他此时接受窗口的大小；如果接受窗口大小还是为0，则发送方再次刷新启动定时器。

1、这里说明下，由于TCP/IP支持全双工传输，因此通信的双方都拥有两个滑动窗口，一个用于接受数据，称之为接收窗口；一个用于发送数据，称之为拥塞窗口(即发送窗口)。指出接受窗口大小的通知我们称之为窗口通告。
2、接收窗口的大小固定吗？
在早期的TCP协议中，接受接受窗口的大小确实是固定的，不过随着网络的快速发展，固定大小的窗口太不灵活了，成为TCP性能瓶颈之一，也就是说，在现在的TCP协议中，接受窗口的大小是根据某种算法动态调整的。
3、接受窗口越大越好吗？
接受窗口如果太小的话，显然这是不行的，这会严重浪费链路利用率，增加丢包率。那是否越大越好呢？答否，当接收窗口达到某个值的时候，再增大的话也不怎么会减少丢包率的了，而且还会更加消耗内存。所以接收窗口的大小必须根据网络环境以及发送发的的拥塞窗口来动态调整。
4、发送窗口和接受窗口相等吗？
接收方在发送确认报文的时候，会告诉发送发自己的接收窗口大小，而发送方的发送窗口会据此来设置自己的发送窗口，但这并不意味着他们就会相等。首先接收方把确认报文发出去的那一刻，就已经在一边处理堆在自己缓存区的数据了，所以一般情况下接收窗口 >= 发送窗口。
我这篇文章算是可以让你知道流量控制的大致原理，如果你想知道更多细节，可以参考TCP/IP详解这本书，挺不错。
计算机网络",
什么是 TCP 三次握手？,"由于在面试中，三次握手是被问的最频繁的面试题，所以本次我们从面试的角度来讲解三次握手

当面试官问你为什么需要有三次握手、三次握手的作用、讲讲三次三次握手的时候，我想很多人会这样回答：
首先很多人会先讲下握手的过程：
1、第一次握手：客户端给服务器发送一个 SYN 报文。
2、第二次握手：服务器收到 SYN 报文之后，会应答一个 SYN+ACK 报文。
3、第三次握手：客户端收到 SYN+ACK 报文之后，会回应一个 ACK 报文。
4、服务器收到 ACK 报文之后，三次握手建立完成。
作用是为了确认双方的接收与发送能力是否正常。
这里我顺便解释一下为啥只有三次握手才能确认双方的接受与发送能力是否正常，而两次却不可以：
第一次握手：客户端发送网络包，服务端收到了。这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。
第二次握手：服务端发包，客户端收到了。这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。不过此时服务器并不能确认客户端的接收能力是否正常。
第三次握手：客户端发包，服务端收到了。这样服务端就能得出结论：客户端的接收、发送能力正常，服务器自己的发送、接收能力也正常。
因此，需要三次握手才能确认双方的接收与发送能力是否正常。
这样回答其实也是可以的，但我觉得，这个过程的我们应该要描述的更详细一点，因为三次握手的过程中，双方是由很多状态的改变的，而这些状态，也是面试官可能会问的点。所以我觉得在回答三次握手的时候，我们应该要描述的详细一点，而且描述的详细一点意味着可以扯久一点。加分的描述我觉得应该是这样：
刚开始客户端处于 closed 的状态，服务端处于 listen 状态。然后
1、第一次握手：客户端给服务端发一个 SYN 报文，并指明客户端的初始化序列号 SN(c)。此时客户端处于 SYN_Send 状态。
2、第二次握手：服务器收到客户端的 SYN 报文之后，会以自己的 SYN 报文作为应答，并且也是指定了自己的初始化序列号 ISN(s)，同时会把客户端的 ISN + 1 作为 ACK 的值，表示自己已经收到了客户端的 SYN，此时服务器处于 SYN_REVD 的状态。
3、第三次握手：客户端收到 SYN 报文之后，会发送一个 ACK 报文，当然，也是一样把服务器的 ISN + 1 作为 ACK 的值，表示已经收到了服务端的 SYN 报文，此时客户端处于 establised 状态。
4、服务器收到 ACK 报文之后，也处于 establised 状态，此时，双方以建立起了链接。

三次握手的作用
三次握手的作用也是有好多的，多记住几个，保证不亏。例如：
1、确认双方的接受能力、发送能力是否正常。
2、指定自己的初始化序列号，为后面的可靠传送做准备。
单单这样还不足以应付三次握手，面试官可能还会问一些其他的问题，例如：
1、（ISN）是固定的吗
三次握手的一个重要功能是客户端和服务端交换ISN(Initial Sequence Number), 以便让对方知道接下来接收数据的时候如何按序列号组装数据。
如果ISN是固定的，攻击者很容易猜出后续的确认号，因此 ISN 是动态生成的。
2、什么是半连接队列
服务器第一次收到客户端的 SYN 之后，就会处于 SYN_RCVD 状态，此时双方还没有完全建立其连接，服务器会把此种状态下请求连接放在一个队列里，我们把这种队列称之为半连接队列。当然还有一个全连接队列，就是已经完成三次握手，建立起连接的就会放在全连接队列中。如果队列满了就有可能会出现丢包现象。

  这里在补充一点关于SYN-ACK 重传次数的问题：　服务器发送完SYN－ACK包，如果未收到客户确认包，服务器进行首次重传，等待一段时间仍未收到客户确认包，进行第二次重传，如果重传次数超 过系统规定的最大重传次数，系统将该连接信息从半连接队列中删除。注意，每次重传等待的时间不一定相同，一般会是指数增长，例如间隔时间为 1s, 2s, 4s, 8s, ….

3、三次握手过程中可以携带数据吗
很多人可能会认为三次握手都不能携带数据，其实第三次握手的时候，是可以携带数据的。也就是说，第一次、第二次握手不可以携带数据，而第三次握手是可以携带数据的。
为什么这样呢？大家可以想一个问题，假如第一次握手可以携带数据的话，如果有人要恶意攻击服务器，那他每次都在第一次握手中的 SYN 报文中放入大量的数据，因为攻击者根本就不理服务器的接收、发送能力是否正常，然后疯狂着重复发 SYN 报文的话，这会让服务器花费很多时间、内存空间来接收这些报文。也就是说，第一次握手可以放数据的话，其中一个简单的原因就是会让服务器更加容易受到攻击了。
而对于第三次的话，此时客户端已经处于 established 状态，也就是说，对于客户端来说，他已经建立起连接了，并且也已经知道服务器的接收、发送能力是正常的了，所以能携带数据页没啥毛病。
计算机网络",
什么是 TCP 四次挥手？,"由于在面试中，三次握手是被问的最频繁的面试题，所以本次我们从面试的角度来讲解四次挥手

四次挥手也一样，千万不要对方一个 FIN 报文，我方一个 ACK 报文，再我方一个 FIN 报文，我方一个 ACK 报文。然后结束，最好是说的详细一点，例如想下面这样就差不多了，要把每个阶段的状态记好，我上次面试就被问了几个了，呵呵。我答错了，还以为自己答对了，当时还解释的头头是道，呵呵。
刚开始双方都处于 establised 状态，假如是客户端先发起关闭请求，则：
1、第一次挥手：客户端发送一个 FIN 报文，报文中会指定一个序列号。此时客户端处于FIN_WAIT1状态。
2、第二次挥手：服务端收到 FIN 之后，会发送 ACK 报文，且把客户端的序列号值 + 1 作为 ACK 报文的序列号值，表明已经收到客户端的报文了，此时服务端处于 CLOSE_WAIT状态。
3、第三次挥手：如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且指定一个序列号。此时服务端处于 LAST_ACK 的状态。
4、第四次挥手：客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答，且把服务端的序列号值 + 1 作为自己 ACK 报文的序列号值，此时客户端处于 TIME_WAIT 状态。需要过一阵子以确保服务端收到自己的 ACK 报文之后才会进入 CLOSED 状态
5、服务端收到 ACK 报文之后，就处于关闭连接了，处于 CLOSED 状态。

这里特别需要主要的就是*TIME_WAIT*这个状态了，这个是面试的高频考点，就是要理解，为什么客户端发送 ACK 之后不直接关闭，而是要等一阵子才关闭。这其中的原因就是，要确保服务器是否已经收到了我们的 ACK 报文，如果没有收到的话，服务器会重新发 FIN 报文给客户端，客户端再次收到 ACK 报文之后，就知道之前的 ACK 报文丢失了，然后再次发送 ACK 报文。
至于 TIME_WAIT 持续的时间至少是一个报文的来回时间。一般会设置一个计时，如果过了这个计时没有再次收到 FIN 报文，则代表对方成功就是 ACK 报文，此时处于 CLOSED 状态。
这里我给出每个状态所包含的含义，有兴趣的可以看看。

  LISTEN – 侦听来自远方TCP端口的连接请求；
  SYN-SENT -在发送连接请求后等待匹配的连接请求；
  SYN-RECEIVED – 在收到和发送一个连接请求后等待对连接请求的确认；
  ESTABLISHED- 代表一个打开的连接，数据可以传送给用户；
  FIN-WAIT-1 – 等待远程TCP的连接中断请求，或先前的连接中断请求的确认；
  FIN-WAIT-2 – 从远程TCP等待连接中断请求；
  CLOSE-WAIT – 等待从本地用户发来的连接中断请求；
  CLOSING -等待远程TCP对连接中断的确认；
  LAST-ACK – 等待原来发向远程TCP的连接中断请求的确认；
  TIME-WAIT -等待足够的时间以确保远程TCP接收到连接中断请求的确认；
  CLOSED – 没有任何连接状态；

最后，在放张三次握手与四次挥手的图

计算机网络",
什么是 HTTP？,"该文章来源于阮一峰都网络日志，我觉得写都非常不错，就授权转载过来了，完善计算机网络这部分都内容

HTTP 协议是互联网的基础协议，也是网页开发的必备知识，最新版本 HTTP/2 更是让它成为技术热点。
本文介绍 HTTP 协议的历史演变和设计思路。

HTTP 是基于 TCP/IP 协议的应用层协议。它不涉及数据包（packet）传输，主要规定了客户端和服务器之间的通信格式，默认使用80端口。
最早版本是1991年发布的0.9版。该版本极其简单，只有一个命令GET。
上面命令表示，TCP 连接（connection）建立后，客户端向服务器请求（request）网页index.html。
协议规定，服务器只能回应HTML格式的字符串，不能回应别的格式。
服务器发送完毕，就关闭TCP连接。
2.1 简介
1996年5月，HTTP/1.0 版本发布，内容大大增加。
首先，任何格式的内容都可以发送。这使得互联网不仅可以传输文字，还能传输图像、视频、二进制文件。这为互联网的大发展奠定了基础。
其次，除了GET命令，还引入了POST命令和HEAD命令，丰富了浏览器与服务器的互动手段。
再次，HTTP请求和回应的格式也变了。除了数据部分，每次通信都必须包括头信息（HTTP header），用来描述一些元数据。
其他的新增功能还包括状态码（status code）、多字符集支持、多部分发送（multi-part type）、权限（authorization）、缓存（cache）、内容编码（content encoding）等。
2.2 请求格式
下面是一个1.0版的HTTP请求的例子。
可以看到，这个格式与0.9版有很大变化。
第一行是请求命令，必须在尾部添加协议版本（HTTP/1.0）。后面就是多行头信息，描述客户端的情况。
2.3 回应格式
服务器的回应如下。
回应的格式是”头信息 + 一个空行（\r\n） + 数据”。其中，第一行是”协议版本 + 状态码（status code） + 状态描述”。
2.4 Content-Type 字段
关于字符的编码，1.0版规定，头信息必须是 ASCII 码，后面的数据可以是任何格式。因此，服务器回应的时候，必须告诉客户端，数据是什么格式，这就是Content-Type字段的作用。
下面是一些常见的Content-Type字段的值。
这些数据类型总称为MIME type，每个值包括一级类型和二级类型，之间用斜杠分隔。
除了预定义的类型，厂商也可以自定义类型。
上面的类型表明，发送的是Debian系统的二进制数据包。
MIME type还可以在尾部使用分号，添加参数。
上面的类型表明，发送的是网页，而且编码是UTF-8。
客户端请求的时候，可以使用Accept字段声明自己可以接受哪些数据格式。
Accept: /
上面代码中，客户端声明自己可以接受任何格式的数据。
MIME type不仅用在HTTP协议，还可以用在其他地方，比如HTML网页。
2.5 Content-Encoding 字段
由于发送的数据可以是任何格式，因此可以把数据压缩后再发送。Content-Encoding字段说明数据的压缩方法。
客户端在请求时，用Accept-Encoding字段说明自己可以接受哪些压缩方法。
2.6 缺点
HTTP/1.0 版的主要缺点是，每个TCP连接只能发送一个请求。发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接。
TCP连接的新建成本很高，因为需要客户端和服务器三次握手，并且开始时发送速率较慢（slow start）。所以，HTTP 1.0版本的性能比较差。随着网页加载的外部资源越来越多，这个问题就愈发突出了。
为了解决这个问题，有些浏览器在请求时，用了一个非标准的Connection字段。
这个字段要求服务器不要关闭TCP连接，以便其他请求复用。服务器同样回应这个字段。
一个可以复用的TCP连接就建立了，直到客户端或服务器主动关闭连接。但是，这不是标准字段，不同实现的行为可能不一致，因此不是根本的解决办法。
1997年1月，HTTP/1.1 版本发布，只比 1.0 版本晚了半年。它进一步完善了 HTTP 协议，一直用到了20年后的今天，直到现在还是最流行的版本。
3.1 持久连接
1.1 版的最大变化，就是引入了持久连接（persistent connection），即TCP连接默认不关闭，可以被多个请求复用，不用声明Connection: keep-alive。
客户端和服务器发现对方一段时间没有活动，就可以主动关闭连接。不过，规范的做法是，客户端在最后一个请求时，发送Connection: close，明确要求服务器关闭TCP连接。
目前，对于同一个域名，大多数浏览器允许同时建立6个持久连接。
3.2 管道机制
1.1 版还引入了管道机制（pipelining），即在同一个TCP连接里面，客户端可以同时发送多个请求。这样就进一步改进了HTTP协议的效率。
举例来说，客户端需要请求两个资源。以前的做法是，在同一个TCP连接里面，先发送A请求，然后等待服务器做出回应，收到后再发出B请求。管道机制则是允许浏览器同时发出A请求和B请求，但是服务器还是按照顺序，先回应A请求，完成后再回应B请求。
3.3 Content-Length 字段
一个TCP连接现在可以传送多个回应，势必就要有一种机制，区分数据包是属于哪一个回应的。这就是Content-length字段的作用，声明本次回应的数据长度。
上面代码告诉浏览器，本次回应的长度是3495个字节，后面的字节就属于下一个回应了。
在1.0版中，Content-Length字段不是必需的，因为浏览器发现服务器关闭了TCP连接，就表明收到的数据包已经全了。
3.4 分块传输编码
使用Content-Length字段的前提条件是，服务器发送回应之前，必须知道回应的数据长度。
对于一些很耗时的动态操作来说，这意味着，服务器要等到所有操作完成，才能发送数据，显然这样的效率不高。更好的处理方法是，产生一块数据，就发送一块，采用”流模式”（stream）取代”缓存模式”（buffer）。
因此，1.1版规定可以不使用Content-Length字段，而使用”分块传输编码”（chunked transfer encoding）。只要请求或回应的头信息有Transfer-Encoding字段，就表明回应将由数量未定的数据块组成。
每个非空的数据块之前，会有一个16进制的数值，表示这个块的长度。最后是一个大小为0的块，就表示本次回应的数据发送完了。下面是一个例子。
3.5 其他功能
1.1版还新增了许多动词方法：PUT、PATCH、HEAD、 OPTIONS、DELETE。
另外，客户端请求的头信息新增了Host字段，用来指定服务器的域名。
有了Host字段，就可以将请求发往同一台服务器上的不同网站，为虚拟主机的兴起打下了基础。
3.6 缺点
虽然1.1版允许复用TCP连接，但是同一个TCP连接里面，所有的数据通信是按次序进行的。服务器只有处理完一个回应，才会进行下一个回应。要是前面的回应特别慢，后面就会有许多请求排队等着。这称为”队头堵塞”（Head-of-line blocking）。
为了避免这个问题，只有两种方法：一是减少请求数，二是同时多开持久连接。这导致了很多的网页优化技巧，比如合并脚本和样式表、将图片嵌入CSS代码、域名分片（domain sharding）等等。如果HTTP协议设计得更好一些，这些额外的工作是可以避免的。
2009年，谷歌公开了自行研发的 SPDY 协议，主要解决 HTTP/1.1 效率不高的问题。
这个协议在Chrome浏览器上证明可行以后，就被当作 HTTP/2 的基础，主要特性都在 HTTP/2 之中得到继承。
2015年，HTTP/2 发布。它不叫 HTTP/2.0，是因为标准委员会不打算再发布子版本了，下一个新版本将是 HTTP/3。
5.1 二进制协议
HTTP/1.1 版的头信息肯定是文本（ASCII编码），数据体可以是文本，也可以是二进制。HTTP/2 则是一个彻底的二进制协议，头信息和数据体都是二进制，并且统称为”帧”（frame）：头信息帧和数据帧。
二进制协议的一个好处是，可以定义额外的帧。HTTP/2 定义了近十种帧，为将来的高级应用打好了基础。如果使用文本实现这种功能，解析数据将会变得非常麻烦，二进制解析则方便得多。
5.2 多工
HTTP/2 复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，而且不用按照顺序一一对应，这样就避免了”队头堵塞”。
举例来说，在一个TCP连接里面，服务器同时收到了A请求和B请求，于是先回应A请求，结果发现处理过程非常耗时，于是就发送A请求已经处理好的部分， 接着回应B请求，完成后，再发送A请求剩下的部分。
这样双向的、实时的通信，就叫做多工（Multiplexing）。
5.3 数据流
因为 HTTP/2 的数据包是不按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。
HTTP/2 将每个请求或回应的所有数据包，称为一个数据流（stream）。每个数据流都有一个独一无二的编号。数据包发送的时候，都必须标记数据流ID，用来区分它属于哪个数据流。另外还规定，客户端发出的数据流，ID一律为奇数，服务器发出的，ID为偶数。
数据流发送到一半的时候，客户端和服务器都可以发送信号（RST_STREAM帧），取消这个数据流。1.1版取消数据流的唯一方法，就是关闭TCP连接。这就是说，HTTP/2 可以取消某一次请求，同时保证TCP连接还打开着，可以被其他请求使用。
客户端还可以指定数据流的优先级。优先级越高，服务器就会越早回应。
5.4 头信息压缩
HTTP 协议不带有状态，每次请求都必须附上所有信息。所以，请求的很多字段都是重复的，比如Cookie和User Agent，一模一样的内容，每次请求都必须附带，这会浪费很多带宽，也影响速度。
HTTP/2 对这一点做了优化，引入了头信息压缩机制（header compression）。一方面，头信息使用gzip或compress压缩后再发送；另一方面，客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了
5.5 服务器推送
HTTP/2 允许服务器未经请求，主动向客户端发送资源，这叫做服务器推送（server push）。
常见场景是客户端请求一个网页，这个网页里面包含很多静态资源。正常情况下，客户端必须收到网页后，解析HTML源码，发现有静态资源，再发出静态资源请求。其实，服务器可以预期到客户端请求网页后，很可能会再请求静态资源，所以就主动把这些静态资源随着网页一起发给客户端了。
计算机网络",
什么是 HTTPS？,"今天这篇文章，讲通过对话的形式，让你由浅入深着知道，为什么 Https 是安全的。





一禅：在每次发送真实数据之前，服务器先生成一把密钥，然后先把密钥传输给客户端。之后服务器给客户端发送真实数据的时候，会用这把密钥对数据进行加密，客户端收到加密数据之后，用刚才收到的密钥进行解密。如图：

当然，如果客户端要给服务器发送数据，也是采用这把密钥来加密，这里为了方便，我采用单方向传输的形式




小白：那万一密钥在传输的过程中被别人截取了怎么吧?
例如：
假如服务器用明文的方式传输密钥给客户端，然后密钥被中间人给捕获了，那么在之后服务器和客户端的加密传输过程中，中间人也可以用他捕获的密钥进行解密。这样的话，加密的数据在中间人看来和明文没啥两样






一禅：这种方法就是，让客户端和服务器都拥有两把钥匙，一把钥匙是公开的(全世界知道都没关系)，我们称之为公钥；另一把钥匙则是保密的(只有自己本人才知道)，我们称之为私钥。这且，用公钥加密的数据，只有对应的私钥才能解密；用私钥加密的数据，只有对应的公钥才能解密。
这样，服务器在给客户端传输数据的过程中，可以用客户端明文给他的公钥进行加密，然后客户端收到后，再用自己的私钥进行解密。客户端给服务器发送数据的时候也一样采取这样的方式。这样就能保持数据的安全传输了。画个图理解一下：








一禅：处理方式就是结合 对称加密+非对称加密这两种方式，我们可以用非对称加密的方式来传输对称加密过程中的密钥，之后我们就可以采取对称加密的方式来传输数据了。具体是这样子的：
服务器用明文的方式给客户端发送自己的公钥，客户端收到公钥之后，会生成一把密钥(对称加密用的)，然后用服务器的公钥对这把密钥进行加密，之后再把密钥传输给服务器，服务器收到之后进行解密，最后服务器就可以安全着得到这把密钥了，而客户端也有同样一把密钥，他们就可以进行对称加密了。



小白：例如：
服务器以明文的方式给客户端传输公钥的时候，中间人截取了这把属于服务器的公钥，并且把中间人自己的公钥冒充服务器的公钥传输给了客户端。
之后客户端就会用中间人的公钥来加密自己生成的密钥。然后把被加密的密钥传输给服务器，这个时候中间人又把密钥给截取了，中间人用自己的私钥对这把被加密的密钥进行解密，解密后中间人就可以获得这把密钥了。
最后中间人再对这把密钥用刚才服务器的公钥进行加密，再发给服务器。如图：

毫无疑问，在这个过程中，中间人获取了对称加密中的密钥，在之后服务器和客户端的对称加密传输中，这些加密的数据对中间人来说，和明文没啥区别。






在刚才的讲解中，我们知道，之所以非对称加密会不安全，是因为客户端不知道这把公钥是否是服务器的，因此，我们需要找到一种策略来证明这把公钥就是服务器的，而不是别人冒充的。
解决这个问题的方式就是使用数字证书，具体是这样的：
我们需要找到一个拥有公信力、大家都认可的认证中心(CA)。
服务器在给客户端传输公钥的过程中，会把公钥以及服务器的个人信息通过Hash算法生成信息摘要。如图

为了防止信息摘要被人调换，服务器还会用CA提供的私钥对信息摘要进行加密来形成数字签名。如图:

并且，最后还会把原来没Hash算法之前的个人信息以及公钥 和 数字签名合并在一起，形成数字证书。如图

当客户端拿到这份数字证书之后，就会用CA提供的公钥来对数字证书里面的数字签名进行解密来得到信息摘要，然后对数字证书里服务器的公钥以及个人信息进行Hash得到另外一份信息摘要。最后把两份信息摘要进行对比，如果一样，则证明这个人是服务器，否则就不是。如图：

这样，就可以保证服务器的公钥安全着交给客户端了。


其实，(有些)服务器一开始就向认证中心申请了这些证书了(有没有看过没有证书的网站在地址栏会被标出警告？)，而客户端是，也会内置这些证书。如图：

当客户端收到服务器传输过来的数据数字证书时，就会在内置的证书列表里，查看是否有解开该数字证书的公钥，如果有则…，如果没有则….


计算机网络",
什么是 DNS？,"DNS 是互联网核心协议之一。不管是上网浏览，还是编程开发，都需要了解一点它的知识。
本文详细介绍DNS的原理，以及如何运用工具软件观察它的运作。我的目标是，读完此文后，你就能完全理解DNS。

DNS （Domain Name System 的缩写）的作用非常简单，就是根据域名查出IP地址。你可以把它想象成一本巨大的电话本。
举例来说，如果你要访问域名math.stackexchange.com，首先要通过DNS查出它的IP地址是151.101.129.69。
如果你不清楚为什么一定要查出IP地址，才能进行网络通信，可以看下这篇：计算机网络五层模型。
计算机网络五层模型
虽然只需要返回一个IP地址，但是DNS的查询过程非常复杂，分成多个步骤。
工具软件dig可以显示整个查询过程。
上面的命令会输出六段信息。

第一段是查询参数和统计。

第二段是查询内容。

上面结果表示，查询域名math.stackexchange.com的A记录，A是address的缩写。
第三段是DNS服务器的答复。

上面结果显示，math.stackexchange.com有四个A记录，即四个IP地址。600是TTL值（Time to live 的缩写），表示缓存时间，即600秒之内不用重新查询。
第四段显示stackexchange.com的NS记录（Name Server的缩写），即哪些服务器负责管理stackexchange.com的DNS记录

上面结果显示stackexchange.com共有四条NS记录，即四个域名服务器，向其中任一台查询就能知道math.stackexchange.com的IP地址是什么。
第五段是上面四个域名服务器的IP地址，这是随着前一段一起返回的。

第六段是DNS服务器的一些传输信息。

上面结果显示，本机的DNS服务器是192.168.1.253，查询端口是53（DNS服务器的默认端口），以及回应长度是305字节。
如果不想看到这么多内容，可以使用+short参数。
上面命令只返回math.stackexchange.com对应的4个IP地址（即A记录）。
下面我们根据前面这个例子，一步步还原，本机到底怎么得到域名math.stackexchange.com的IP地址。
首先，本机一定要知道DNS服务器的IP地址，否则上不了网。通过DNS服务器，才能知道某个域名的IP地址到底是什么。

DNS服务器的IP地址，有可能是动态的，每次上网时由网关分配，这叫做DHCP机制；也有可能是事先指定的固定地址。Linux系统里面，DNS服务器的IP地址保存在/etc/resolv.conf文件。
上例的DNS服务器是192.168.1.253，这是一个内网地址。有一些公网的DNS服务器，也可以使用，其中最有名的就是Google的8.8.8.8和Level 3的4.2.2.2。
本机只向自己的DNS服务器查询，dig命令有一个@参数，显示向其他DNS服务器查询的结果。
上面命令指定向DNS服务器4.2.2.2查询。
DNS服务器怎么会知道每个域名的IP地址呢？答案是分级查询。
请仔细看前面的例子，每个域名的尾部都多了一个点。

比如，域名math.stackexchange.com显示为math.stackexchange.com.。这不是疏忽，而是所有域名的尾部，实际上都有一个根域名。
举例来说，www.example.com真正的域名是www.example.com.root，简写为www.example.com.。因为，根域名.root对于所有域名都是一样的，所以平时是省略的。
根域名的下一级，叫做”顶级域名”（top-level domain，缩写为TLD），比如.com、.net；再下一级叫做”次级域名”（second-level domain，缩写为SLD），比如www.example.com里面的.example，这一级域名是用户可以注册的；再下一级是主机名（host），比如www.example.com里面的www，又称为”三级域名”，这是用户在自己的域里面为服务器分配的名称，是用户可以任意分配的。
总结一下，域名的层级结构如下。
DNS服务器根据域名的层级，进行分级查询。
需要明确的是，每一级域名都有自己的NS记录，NS记录指向该级域名的域名服务器。这些服务器知道下一级域名的各种记录。
所谓”分级查询”，就是从根域名开始，依次查询每一级域名的NS记录，直到查到最终的IP地址，过程大致如下。
1、从”根域名服务器”查到”顶级域名服务器”的NS记录和A记录（IP地址）
2、从”顶级域名服务器”查到”次级域名服务器”的NS记录和A记录（IP地址）
3、从”次级域名服务器”查出”主机名”的IP地址
仔细看上面的过程，你可能发现了，没有提到DNS服务器怎么知道”根域名服务器”的IP地址。回答是”根域名服务器”的NS记录和IP地址一般是不会变化的，所以内置在DNS服务器里面。
下面是内置的根域名服务器IP地址的一个例子。

上面列表中，列出了根域名（.root）的三条NS记录A.ROOT-SERVERS.NET、B.ROOT-SERVERS.NET和C.ROOT-SERVERS.NET，以及它们的IP地址（即A记录）198.41.0.4、192.228.79.201、192.33.4.12。
另外，可以看到所有记录的TTL值是3600000秒，相当于1000小时。也就是说，每1000小时才查询一次根域名服务器的列表。
目前，世界上一共有十三组根域名服务器，从A.ROOT-SERVERS.NET一直到M.ROOT-SERVERS.NET。
dig命令的+trace参数可以显示DNS的整个分级查询过程。
上面命令的第一段列出根域名.的所有NS记录，即所有根域名服务器。

根据内置的根域名服务器IP地址，DNS服务器向所有这些IP地址发出查询请求，询问math.stackexchange.com的顶级域名服务器com.的NS记录。最先回复的根域名服务器将被缓存，以后只向这台服务器发请求。
接着是第二段

上面结果显示.com域名的13条NS记录，同时返回的还有每一条记录对应的IP地址。
然后，DNS服务器向这些顶级域名服务器发出查询请求，询问math.stackexchange.com的次级域名stackexchange.com的NS记录。

上面结果显示stackexchange.com有四条NS记录，同时返回的还有每一条NS记录对应的IP地址。
然后，DNS服务器向上面这四台NS服务器查询math.stackexchange.com的主机名。

上面结果显示，math.stackexchange.com有4条A记录，即这四个IP地址都可以访问到网站。并且还显示，最先返回结果的NS服务器是ns-463.awsdns-57.com，IP地址为205.251.193.207。
dig命令可以单独查看每一级域名的NS记录。
+short参数可以显示简化的结果。
八、DNS的记录类型
域名与IP之间的对应关系，称为”记录”（record）。根据使用场景，”记录”可以分成不同的类型（type），前面已经看到了有A记录和NS记录。
常见的DNS记录类型如下。
（1） A：地址记录（Address），返回域名指向的IP地址。
（2） NS：域名服务器记录（Name Server），返回保存下一级域名信息的服务器地址。该记录只能设置为域名，不能设置为IP地址。
（3）MX：邮件记录（Mail eXchange），返回接收电子邮件的服务器地址。
（4）CNAME：规范名称记录（Canonical Name），返回另一个域名，即当前查询的域名是另一个域名的跳转，详见下文。
（5）PTR：逆向查询记录（Pointer Record），只用于从IP地址查询域名，详见下文。
一般来说，为了服务的安全可靠，至少应该有两条NS记录，而A记录和MX记录也可以有多条，这样就提供了服务的冗余性，防止出现单点失败。
CNAME记录主要用于域名的内部跳转，为服务器配置提供灵活性，用户感知不到。举例来说，facebook.github.io这个域名就是一个CNAME记录
上面结果显示，facebook.github.io的CNAME记录指向github.map.fastly.net。也就是说，用户查询facebook.github.io的时候，实际上返回的是github.map.fastly.net的IP地址。这样的好处是，变更服务器IP地址的时候，只要修改github.map.fastly.net这个域名就可以了，用户的facebook.github.io域名不用修改。
由于CNAME记录就是一个替换，所以域名一旦设置CNAME记录以后，就不能再设置其他记录了（比如A记录和MX记录），这是为了防止产生冲突。举例来说，foo.com指向bar.com，而两个域名各有自己的MX记录，如果两者不一致，就会产生问题。由于顶级域名通常要设置MX记录，所以一般不允许用户对顶级域名设置CNAME记录。
PTR记录用于从IP地址反查域名。dig命令的-x参数用于查询PTR记录。
上面结果显示，192.30.252.153这台服务器的域名是pages.github.com。
逆向查询的一个应用，是可以防止垃圾邮件，即验证发送邮件的IP地址，是否真的有它所声称的域名。
dig命令可以查看指定的记录类型。
除了dig，还有一些其他小工具也可以使用。
（1）host 命令
host命令可以看作dig命令的简化版本，返回当前请求域名的各种记录。
host命令也可以用于逆向查询，即从IP地址查询域名，等同于dig -x \。
（2）nslookup 命令
nslookup命令用于互动式地查询域名记录。
（3）whois 命令
whois命令用来查看域名的注册情况。
计算机网络",
什么是 DHCP ？,"对于我们平时上网的电脑的 ip 是如何来的呢？一种简单的方法就是我们自己来配置了

显然，这里有两种配置方式，一种是自动获取 ip 地址，一种是我们手动来设置，我相信大部分人都是通过自动获取的方式来得到 ip 的，那么问题来了，它是如何自动获得到的呢？
可能很多人都知道，是通过 DHCP 服务器来获取 ip 的，那么问题来了，你要给 DHCP 服务器发报文来获取 ip，那么你知道 DHCP 服务器的 ip 是多少吗？自己客户端的源 ip 又是多少呢？现在啥也不知道，该如何发送报文呢？
为了解决这个问题，客户端会发送一个广播，我们知道，广播报文是会发送局域网内的所有其他主机的，广播的目的 ip 是 255.255.255.255，目的端口是 68，为了让别人知道它是来请求一个 ip 的，我们的客户端会把 0.0.0.0 作为自己的源 ip，源端口是 67。意在告诉别人：我现在啥也没有，急需一个 ip，哪位老铁能给我提供一个 ip。

我们把这个请求 ip 的报文称之为 discover 报文。

  这里提醒一些，这里发送的报文都是采用 UDP 报文，而不是 TCP 报文哈，下同。

当 DHCP 服务器收到这个报文之后，一看源地址是 0.0.0.0，就知道生意来了，知道这是一个请求 ip 的报文，DHCP 服务器就会给它提供一个 ip，包括 ip 地址，子网掩码，网关，ip 的有效期等信息。
有人可能会问，只有源 ip 为 0.0.0.0 的信息，我们怎么把报文发送到它的手里呢？这不，我们每台电脑不都有 Mac 地址吗？在 discover 报文中，就会包含它的 MAC 地址了，DHCP 服务器，只需要发一个广播报文就可以了，广播报文的源ip是 DHCP  服务器自己的 ip，源端口是 67，目的地址是 255.255.255.255，目的端口是 68

我们把 DHCP 提供 ip 地址的报文称之为offer报文。
我们知道，有可能不止一台 DHCP 服务器收到了 discover 请求报文，也就是说，我们的主机可能会收到多个 offer 报文，所以呢，我们的主机会选择其中一个心仪的 offer 报文来作为自己的 ip，一般是选择最先收到的 offer 报文，选择好之后，会给对应的 DHCP 服务器次发送一个 request 报文，意在告诉它，我看中了你的报文。
DHCP 收到 request 报文之后，会给它回复一个 ACK 报文，并且把这个分配出去的 ip 进行登记（例如把这个 ip 标记为已使用状态）。
当我们的主机收到 ACK 报文之后，就可以开始冲浪在网上冲浪了。
这里可能有人会说，如果 DHCP 服务器没有在我们所在的局域网里怎么办？这个时候，这个 discover 报文 就会通过我们的网关来进行传递，并且会把源 ip 替换成网络的 ip，源端口是 68，这里涉及到 NAT 地址到转换，不懂的可以看我之前的一篇文章。
谈谈NAT：什么？全球IP和私有IP是什么鬼？
谈谈NAT：什么？全球IP和私有IP是什么鬼？
DHCP 服务器收到报文之后，就可以根据源端口 68 来判断这是一个 discover 请求报文了。就会把 offer 发给网关，网关再发给我们的主机。

在DHCP客户端的租约时间到达 1/2 时，客户端会向为它分配 IP 地址的DHCP服务器发送 request 单播报文，以进行 IP 租约的更新。如果服务器判断客户端可以继续使用这个 IP 地址，就回复 ACK 报文，通知客户端更新租约成功。如果此IP地址不能再分配给客户端，则回复 NAK 报文，通知客户端续约失败。
如果客户端在租约到达 1/2 时续约失败，客户端会在租约到 7/8 时间时，广播发送 request 报文进行续约。DHCP服务器处理同首次分配 IP 地址的流程。
这个过程中，涉及到听多种报文，为了篇幅不要太长，我有些报文没有详细说，这里为了方便大家查看，我把所有报文都总结了一下
DHCP Discove：DHCP客户端请求地址时，并不知道DHCP服务器的位置，因此DHCP客户端会在本地网络内以广播方式发送请求报文，这个报文成为Discover报文，目的是发现网络中的DHCP服务器，所有收到Discover报文的DHCP服务器都会发送回应报文，DHCP客户端据此可以知道网络中存在的DHCP服务器的位置。
DHCP Offe：DHCP服务器收到Discover报文后，就会在所配置的地址池中查找一个合适的IP地址，加上相应的租约期限和其他配置信息（如网关、DNS服务器等），构造一个Offer报文，发送给用户。
DHCP Request：DHCP客户端可能会收到很多Offer，所以必须在这些回应中选择一个。Client通常选择第一个回应Offer报文的服务器作为自己的目标服务器，并回应一个广播Request报文，通告选择的服务器。
DHCP ACK：DHCP服务器收到Request报文后，根据Request报文中携带的用户MAC来查找有没有相应的租约记录，如果有则发送ACK报文作为回应，通知用户可以使用分配的IP地址。
DHCP NAK： 如果DHCP服务器收到Request报文后，没有发现有相应的租约记录或者由于某些原因无法正常分配IP地址，则发送NAK报文作为回应，通知用户无法分配合适的IP地址。
DHCP Release：当用户不再需要使用分配IP地址时，就会主动向DHCP服务器发送Release报文，告知服务器用户不再需要分配IP地址，DHCP服务器会释放被绑定的租约。
DHCP Decline： DHCP客户端收到DHCP服务器回应的ACK报文后，通过地址冲突检测发现服务器分配的地址冲突或者由于其他原因导致不能使用，则发送Decline报文，通知服务器所分配的IP地址不可用
DHCP Inform：DHCP客户端如果需要从DHCP服务器端获取更为详细的配置信息，则发送Inform报文向服务器进行请求，服务器收到该报文后，将根据租约进行查找，找到相应的配置信息后，发送ACK报文回应DHCP客户端。
计算机网络",
什么是广播路由算法？,"之前说的 ARP 协议，DHCP 协议等，都聊到了广播，今天我们就来深入聊一聊广播相关的算法，还是值得一看。

对于广播，我相信在现实生活中我们时常都能接触到，例如学校一言不合就响起了校歌，搞的全校的人都能够听到，想假装没听到都不行。
假如我们把学校比作一个局域网的话，某台主机发起了一个广播，意味着局域网内的其他所有主机都会收到这个广播，那发起广播的主机是如何选择路径来给其他主机发送广播分组的呢？考虑下面由几个节点组成的网络：

假如节点 R1 要做一个广播给 R2, R3, R4发广播分组，显然，一种很简单的方法就是R1给 R2, R3, R4三个节点分别发一次广播分组，这意味着R1一共要发送三次同样的广播分组。

大家想一个问题：这种发送方式你觉得合理吗？
是的，这种发送方式在实现上很简单，源节点(R1)每次带上目的节点的地址，然后发送给它就行了。
不过这种方式在效率上是极低的，例如，R1发送的这三个广播分组都会经过同一段链路(R1-R2这段链路)，而且R2要是再连接上n个节点的话，代表着这R1需要再发送n次广播分组，这n个报文也会经过同一段链路。
为了解决这个问题，我们或许可以这样做：就是R1把广播分组发给他的邻居节点R2，然后R1就不管了，R2再把报文发送给他的所有邻居节点R3, R4(除了从其接收该分组的那个邻居R1)。

显然这种方式也是挺不错的，R1只发送了一次广播分组，而且R1-R2这段链路也不会出现同一个广播分组重复经过的情况。嗯，这很nice。
不过，这种给所有邻居节点发送广播分组的方式够优雅吗？
看下面的一个网络组成：

按照刚才的方法，R1会给R2发送广播分组，接着R2会给R3, R4发送广播分组。刚才我们说过，收到广播分组的节点会给他的所有邻居发送报文(除了从其接受到该报文的那个邻居)。
所以这个时候 R3会给R4发送广播分组文，而R4接收到R3的广播分组之后，R4会给R2发送广播分组，R2收到R4的广播分组之后 ，也会给R3再次发送广播分组…..
如果节点中形成了一个圈，那么就会像上面那样，节点之间不停着发送广播分组，这时网络上充斥着大量重复的广播分组，这将会严重影响资源的利用。
我们也把这种情况称之为广播风暴。
因此，我们必须想出某种策略，来控制这种广播风暴。
一种很简单的方法，就是给这一份广播分组做一个标记。例如，源节点(发起广播的节点)可以将其地址以及广播序号放入这个广播分组中，然后发送给他的所有邻居节点，每个节点会维护它已经收到的、转发的源地址和广播分组的序号列表。
当节点收到一个广播分组时，会检查这个广播分组是否之前接收过(可以通过源地址、报文序号来检查)，如果接收过，那么就把该广播分组丢弃，否则，把该广播分组接收，且向所有邻居节点转发。
例如对于下面由7个节点组成是网络

如果 节点 A 要做一个广播，那么 A就会给他的邻居节点B,C发一份广播分组，B，C也会给他的邻居节点发送一个广播分组。意味着B会给 C,D发送广播分组，而 C也会给 B,E,F发送一份广播分组：

当B收到C发给他的报文时，B检测到已经有了该报文，所以B会丢弃C发送给他的广播分组，C也一样会丢弃B发送给他的广播分组。图中青色的箭头代表该广播分组会被丢弃。

从图中不难看出，就算节点之间形成了圈，但也不会出现节点之间循环转发的情况。
虽然该方法简单 ，但确实有效着控制了广播风暴，当然，这只是控制广播风暴的方法之一，实际上还有其他方法，在此我就不说了。
虽然上面的那种方法有效着控制了广播风暴，但也是存在着很多的冗余广播分组(那些被丢弃的广播分组就是冗余的广播分组)。

如果可以，我想让每个节点仅接收一次广播分组，也不用 考虑丢弃广播分组，所以理想的情况应该是这样：

有没有一种方法，可以让广播分组像上面这种情况来传送呢？请大家看下面一个图：

如果把节点当作一个图的顶点，大家观察下左边的图与右边的图有什么联系。
右边的图不就是左边图的生成树吗？(学了这么多年的生成树，终于给用到了)，如果我们给每一段链路加上相应的费用的话，那么我们最理想的情况就是找到一颗最小生成树。
所以，我们最理想的情况就是让广播报文在最小生成树的路径中传送，于是 ，我们现在的问题就是找出这些节点组成的网络中的最小生成树。
那么，如何构造一颗生成树呢？下面提供一种基于某个中心的方法来建立一颗生成树。注意，是生成树，不是最小生成树。
该方法是这样的：我们先选出一个中心节点，然后其他节点向这个中心节点发送加入树报文，加入树报文经过的路径，都会被嫁接到生成树上。我举个例子吧，好理解点。例如对于这个网络结构：

我们选择 E为中心点，然后其他节点给E发送加入树报文：
1、F节点给E发送加入树报文，此时E-F链路成为初始的生成树，如下图(红色路径表示生成树)

2、接着B给E发送加入树报文，假设B经过的路径是B->D->E。此时路径B-D-E也加入了生成树。

注：D不用在不用在发送加入树报文了，因此他此时已经在生成树里了。
3、接着C给E发送加入树报文，C-E加入生成树。

4、接着，A给E发送报文，假设A选择的路径是A->C->E。不过当A的报文到达C之后，由于原本C-E就在生成树里面了，所以A的报文不用经过C-E，A-C就加入到生成树了。

5、最后G通过D加入生成树。

到此，生成树构建完毕，此时生成树如下：

然后在广播的时候，就可以沿着这条路径来转发复制广播报文了。
计算机网络",
什么是数字签名？,"该文章来源于阮一峰都网络日志，我觉得写都非常不错，就授权转载过来了，完善计算机网络这部分都内容

今天，我读到一篇好文章。
它用图片通俗易懂地解释了，”数字签名”（digital signature）和”数字证书”（digital certificate）到底是什么。
我对这些问题的理解，一直是模模糊糊的，很多细节搞不清楚。读完这篇文章后，发现思路一下子就理清了。为了加深记忆，我把文字和图片都翻译出来了
1、

鲍勃有两把钥匙，一把是公钥，另一把是私钥。
2、

鲍勃把公钥送给他的朋友们—-帕蒂、道格、苏珊—-每人一把。
3、

苏珊要给鲍勃写一封保密的信。她写完后用鲍勃的公钥加密，就可以达到保密的效果。
4、

鲍勃收信后，用私钥解密，就看到了信件内容。这里要强调的是，只要鲍勃的私钥不泄露，这封信就是安全的，即使落在别人手里，也无法解密。
5、

鲍勃给苏珊回信，决定采用”数字签名”。他写完后先用Hash函数，生成信件的摘要（digest）。
6、

然后，鲍勃使用私钥，对这个摘要加密，生成”数字签名”（signature）。
7、

鲍勃将这个签名，附在信件下面，一起发给苏珊。
8、

苏珊收信后，取下数字签名，用鲍勃的公钥解密，得到信件的摘要。由此证明，这封信确实是鲍勃发出的。
9、

苏珊再对信件本身使用Hash函数，将得到的结果，与上一步得到的摘要进行对比。如果两者一致，就证明这封信未被修改过。
10、

复杂的情况出现了。道格想欺骗苏珊，他偷偷使用了苏珊的电脑，用自己的公钥换走了鲍勃的公钥。此时，苏珊实际拥有的是道格的公钥，但是还以为这是鲍勃的公钥。因此，道格就可以冒充鲍勃，用自己的私钥做成”数字签名”，写信给苏珊，让苏珊用假的鲍勃公钥进行解密。
11、

后来，苏珊感觉不对劲，发现自己无法确定公钥是否真的属于鲍勃。她想到了一个办法，要求鲍勃去找”证书中心”（certificate authority，简称CA），为公钥做认证。证书中心用自己的私钥，对鲍勃的公钥和一些相关信息一起加密，生成”数字证书”（Digital Certificate）。
12、

鲍勃拿到数字证书以后，就可以放心了。以后再给苏珊写信，只要在签名的同时，再附上数字证书就行了。
13、

苏珊收信后，用CA的公钥解开数字证书，就可以拿到鲍勃真实的公钥了，然后就能证明”数字签名”是否真的是鲍勃签的。
14、

下面，我们看一个应用”数字证书”的实例：https协议。这个协议主要用于网页加密。
1、

首先，客户端向服务器发出加密请求。
2、

服务器用自己的私钥加密网页以后，连同本身的数字证书，一起发送给客户端。
3、

客户端（浏览器）的”证书管理器”，有”受信任的根证书颁发机构”列表。客户端会根据这张列表，查看解开数字证书的公钥是否在列表之内。
4、

如果数字证书记载的网址，与你正在浏览的网址不一致，就说明这张证书可能被冒用，浏览器会发出警告。
5、

如果这张数字证书不是由受信任的机构颁发的，浏览器会发出另一种警告。
6、

如果数字证书是可靠的，客户端就可以使用证书中的服务器公钥，对信息进行加密，然后与服务器交换加密信息。
计算机网络",
什么是 SSL/TLS 协议？,"上篇文章我们讲解了 HTTPS，其实 HTTPS 就是 HTTP 协议再套上一层 SSL 加密，这篇文章来详细讲解下 SSL 的运行机制，该文章来自于阮一峰的网络日志，我觉得写的不错，所以授权过来

互联网的通信安全，建立在SSL/TLS协议之上。
本文简要介绍SSL/TLS协议的运行机制。文章的重点是设计思想和运行过程，不涉及具体的实现细节。如果想了解这方面的内容，请参阅RFC文档。
RFC文档

一、作用
不使用SSL/TLS的HTTP通信，就是不加密的通信。所有信息明文传播，带来了三大风险。
（1） 窃听风险（eavesdropping）：第三方可以获知通信内容。
（2） 篡改风险（tampering）：第三方可以修改通信内容。
（3） 冒充风险（pretending）：第三方可以冒充他人身份参与通信。
SSL/TLS协议是为了解决这三大风险而设计的，希望达到：
（1） 所有信息都是加密传播，第三方无法窃听。
（2） 具有校验机制，一旦被篡改，通信双方会立刻发现。
（3） 配备身份证书，防止身份被冒充。
互联网是开放环境，通信双方都是未知身份，这为协议的设计带来了很大的难度。而且，协议还必须能够经受所有匪夷所思的攻击，这使得SSL/TLS协议变得异常复杂。
二、历史
互联网加密通信协议的历史，几乎与互联网一样长。
1994年，NetScape公司设计了SSL协议（Secure Sockets Layer）的1.0版，但是未发布。
1995年，NetScape公司发布SSL 2.0版，很快发现有严重漏洞。
1996年，SSL 3.0版问世，得到大规模应用。
1999年，互联网标准化组织ISOC接替NetScape公司，发布了SSL的升级版TLS 1.0版。
TLS
2006年和2008年，TLS进行了两次升级，分别为TLS 1.1版和TLS 1.2版。最新的变动是2011年TLS 1.2的修订版。
修订版
目前，应用最广泛的是TLS 1.0，接下来是SSL 3.0。但是，主流浏览器都已经实现了TLS 1.2的支持。
TLS 1.0通常被标示为SSL 3.1，TLS 1.1为SSL 3.2，TLS 1.2为SSL 3.3。
三、基本的运行过程
SSL/TLS协议的基本思路是采用公钥加密法，也就是说，客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。
公钥加密法
但是，这里有两个问题。
（1）如何保证公钥不被篡改？
解决方法：将公钥放在数字证书中。只要证书是可信的，公钥就是可信的。
数字证书
（2）公钥加密计算量太大，如何减少耗用的时间？
解决方法：每一次对话（session），客户端和服务器端都生成一个”对话密钥”（session key），用它来加密信息。由于”对话密钥”是对称加密，所以运算速度非常快，而服务器公钥只用于加密”对话密钥”本身，这样就减少了加密运算的消耗时间。
因此，SSL/TLS协议的基本过程是这样的：
（1） 客户端向服务器端索要并验证公钥。
（2） 双方协商生成”对话密钥”。
（3） 双方采用”对话密钥”进行加密通信。
上面过程的前两步，又称为”握手阶段”（handshake）。
四、握手阶段的详细过程

“握手阶段”涉及四次通信，我们一个个来看。需要注意的是，”握手阶段”的所有通信都是明文的。
4.1 客户端发出请求（ClientHello）
首先，客户端（通常是浏览器）先向服务器发出加密通信的请求，这被叫做ClientHello请求。
在这一步，客户端主要向服务器提供以下信息。
（1） 支持的协议版本，比如TLS 1.0版。
（2） 一个客户端生成的随机数，稍后用于生成”对话密钥”。
（3） 支持的加密方法，比如RSA公钥加密。
（4） 支持的压缩方法。
这里需要注意的是，客户端发送的信息之中不包括服务器的域名。也就是说，理论上服务器只能包含一个网站，否则会分不清应该向客户端提供哪一个网站的数字证书。这就是为什么通常一台服务器只能有一张数字证书的原因。
对于虚拟主机的用户来说，这当然很不方便。2006年，TLS协议加入了一个Server Name Indication扩展，允许客户端向服务器提供它所请求的域名。
Server Name Indication扩展
4.2 服务器回应（SeverHello）
服务器收到客户端请求后，向客户端发出回应，这叫做SeverHello。服务器的回应包含以下内容。
（1） 确认使用的加密通信协议版本，比如TLS 1.0版本。如果浏览器与服务器支持的版本不一致，服务器关闭加密通信。
（2） 一个服务器生成的随机数，稍后用于生成”对话密钥”。
（3） 确认使用的加密方法，比如RSA公钥加密。
（4） 服务器证书。
除了上面这些信息，如果服务器需要确认客户端的身份，就会再包含一项请求，要求客户端提供”客户端证书”。比如，金融机构往往只允许认证客户连入自己的网络，就会向正式客户提供USB密钥，里面就包含了一张客户端证书。
4.3 客户端回应
客户端收到服务器回应以后，首先验证服务器证书。如果证书不是可信机构颁布、或者证书中的域名与实际域名不一致、或者证书已经过期，就会向访问者显示一个警告，由其选择是否还要继续通信。
如果证书没有问题，客户端就会从证书中取出服务器的公钥。然后，向服务器发送下面三项信息。
（1） 一个随机数。该随机数用服务器公钥加密，防止被窃听。
（2） 编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送。
（3） 客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时也是前面发送的所有内容的hash值，用来供服务器校验。
上面第一项的随机数，是整个握手阶段出现的第三个随机数，又称”pre-master key”。有了它以后，客户端和服务器就同时有了三个随机数，接着双方就用事先商定的加密方法，各自生成本次会话所用的同一把”会话密钥”。
至于为什么一定要用三个随机数，来生成”会话密钥”，dog250解释得很好：
dog250

  “不管是客户端还是服务器，都需要随机数，这样生成的密钥才不会每次都一样。由于SSL协议中证书是静态的，因此十分有必要引入一种随机因素来保证协商出来的密钥的随机性。
  对于RSA密钥交换算法来说，pre-master-key本身就是一个随机数，再加上hello消息中的随机，三个随机数通过一个密钥导出器最终导出一个对称密钥。
  pre master的存在在于SSL协议不信任每个主机都能产生完全随机的随机数，如果随机数不随机，那么pre master secret就有可能被猜出来，那么仅适用pre master secret作为密钥就不合适了，因此必须引入新的随机因素，那么客户端和服务器加上pre master secret三个随机数一同生成的密钥就不容易被猜出了，一个伪随机可能完全不随机，可是是三个伪随机就十分接近随机了，每增加一个自由度，随机性增加的可不是一。”

此外，如果前一步，服务器要求客户端证书，客户端会在这一步发送证书及相关信息。
4.4 服务器的最后回应
服务器收到客户端的第三个随机数pre-master key之后，计算生成本次会话所用的”会话密钥”。然后，向客户端最后发送下面信息。
（1）编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送。
（2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时也是前面发送的所有内容的hash值，用来供客户端校验。
至此，整个握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的HTTP协议，只不过用”会话密钥”加密内容。

计算机网络",
什么是 SQL 注入攻击？,"SQL注入就是通过把SQL命令插入到Web表单提交或输入域名或页面请求的查询字符串，服务器拿到这个字符串之后，会把这个字符串作为 sql 的执行参数去数据库查询，然而这个参数是恶意的，以至于服务器执行这条 sql 命令之后，出现了问题。
下面直接弄个案例吧，这样容易理解一些。
比如，在一个登录界面，要求输入用户名和密码，可以这样输入实现免帐号登录：
用户一旦点击登录，如若没有做特殊处理，那么这个非法用户就很得意的登陆进去了。
这是为什么呢?
下面我们分析一下：从理论上说，后台认证程序中可能会有如下的SQL语句：
因此，当输入了上面的用户名和密码，把参数代进去，则上面的SQL语句变成：
分析上述SQL语句我们知道，username=‘ or 1=1 这个语句一定会成功；然后后面加两个-，在 sql 中，两个 -这意味着注释，它将后面的语句注释，让他们不起作用。这样，后面的and password=’’语句将不会执行，所以上述语句永远都能正确执行，用户轻易骗过系统，获取合法身份。
应对方法
(1). 参数绑定
使用预编译手段，绑定参数是最好的防SQL注入的方法。目前许多的ORM框架及JDBC等都实现了SQL预编译和参数绑定功能，攻击者的恶意SQL会被当做SQL的参数而不是SQL命令被执行。在mybatis的mapper文件中，对于传递的参数我们一般是使用 # 和$来获取参数值。
当使用#时，变量是占位符，就是一般我们使用javajdbc的PrepareStatement时的占位符，所有可以防止sql注入；当使用 $时，变量就是直接追加在sql中，一般会有sql注入问题。
(2). 使用正则表达式过滤传入的参数，例如把出现双-的过滤掉等等。
计算机网络",
什么是 XSS 攻击？,"XSS是一种经常出现在web应用中的计算机安全漏洞，与SQL注入一起成为web中最主流的攻击方式。
XSS是指恶意攻击者利用网站没有对用户提交数据进行转义处理或者过滤不足的缺点，进而添加一些脚本代码嵌入到web页面中去，使别的用户访问都会执行相应的嵌入代码，从而盗取用户资料、利用用户身份进行某种动作或者对访问者进行病毒侵害的一种攻击方式。
1). XSS攻击的危害
盗取各类用户帐号，如机器登录帐号、用户网银帐号、各类管理员帐号
控制企业数据，包括读取、篡改、添加、删除企业敏感数据的能力
盗窃企业重要的具有商业价值的资料
非法转账
强制发送电子邮件
网站挂马
控制受害者机器向其它网站发起攻击
2). 原因解析
主要原因：过于信任客户端提交的数据！
解决办法：不信任任何客户端提交的数据，只要是客户端提交的数据就应该先进行相应的过滤处理然后方可进行下一步的操作。
进一步分析细节：客户端提交的数据本来就是应用所需要的，但是恶意攻击者利用网站对客户端提交数据的信任，在数据中插入一些符号以及javascript代码，那么这些数据将会成为应用代码中的一部分了，那么攻击者就可以肆无忌惮地展开攻击啦，因此我们绝不可以信任任何客户端提交的数据！！！
3). XSS 攻击分类
(1). 反射性XSS攻击 (非持久性XSS攻击)
漏洞产生的原因是攻击者注入的数据反映在响应中。一个典型的非持久性XSS攻击包含一个带XSS攻击向量的链接(即每次攻击需要用户的点击)，例如，正常发送消息：
接收者将会接收信息并显示Hello,World；但是，非正常发送消息：
接收者接收消息显示的时候将会弹出警告窗口！
(2). 持久性XSS攻击 (留言板场景)
XSS攻击向量(一般指XSS攻击代码)存储在网站数据库，当一个页面被用户打开的时候执行。也就是说，每当用户使用浏览器打开指定页面时，脚本便执行。
与非持久性XSS攻击相比，持久性XSS攻击危害性更大。从名字就可以了解到，持久性XSS攻击就是将攻击代码存入数据库中，然后客户端打开时就执行这些攻击代码。
例如，留言板表单中的表单域：
正常操作流程是：用户是提交相应留言信息 —— 将数据存储到数据库 —— 其他用户访问留言板，应用去数据并显示；而非正常操作流程是攻击者在value填写:
并将数据提交、存储到数据库中；当其他用户取出数据显示的时候，将会执行这些攻击性代码。
4). 修复漏洞方针
漏洞产生的根本原因是 太相信用户提交的数据，对用户所提交的数据过滤不足所导致的，因此解决方案也应该从这个方面入手，具体方案包括：
将重要的cookie标记为http only, 这样的话Javascript 中的document.cookie语句就不能获取到cookie了（如果在cookie中设置了HttpOnly属性，那么通过js脚本将无法读取到cookie信息，这样能有效的防止XSS攻击）；
表单数据规定值的类型，例如：年龄应为只能为int、name只能为字母数字组合。。。。
对数据进行Html Encode 处理
过滤或移除特殊的Html标签，例如: < script >, < iframe > , < for <, > for>, &quot for
过滤JavaScript 事件的标签，例如 “οnclick=”, “onfocus” 等等。
需要注意的是，在有些应用中是允许html标签出现的，甚至是javascript代码出现。因此，我们在过滤数据的时候需要仔细分析哪些数据是有特殊要求（例如输出需要html代码、javascript代码拼接、或者此表单直接允许使用等等），然后区别处理！
计算机网络",
什么是 NAT 网络地址转换协议？,"可能你们会经常听到全球 IP(外网)和私有 IP(内网)，他们的区别是什么呢？今天这篇文章来简单讲讲这到底是怎么回事。
我们都知道，IPv4中的IP地址的数量是有限的，每次把一部分地址分配出去，那么就意味着能够用来分配的IP地址就更少了，而且随着现在手机，电脑等的快速发展，如果每个手机或者电脑都要求一个IP地址，那么显然IP地址是不够用的。
为了解决这个问题，我们可以采取这样的策略：例如对于一个公司来说，每个公司都会有一个属于自己公司的内网(也可以称之为局域网)。
假如我们给这个公司A分配了一个IP=192.168.1.1。我们把这个IP作为这个公司内网的网关吧。

在公司A的内网里面有3台电脑，如果这三台电脑要上网的话，我们需要给他分配一个IP，那么我们一定需要去申请3个IP地址来使用吗？
答否。我们不一定需要去申请3个IP的，在我们这个内网里，我们可以指定自己的规则，例如，我们可以给这三台电脑随便分配三个IP(请注意，这三个IP不是去申请的，而且我自己随意给它分配的)。分别分配电脑A = 192.168.1.2  电脑B = 192.168.1.3 电脑C = 192.168.1.4

假如电脑A想要访问百度，百度的IP我们假设为：172.168.30.3

我们都知道，电脑A的IP是我们虚构的，实际上可能并不存在这样一个IP，如果用电脑A的IP去访问百度，那肯定行不通。
我们也知道，由于百度和电脑A不在一个局域网内，所以A要访问百度，那么必须得经过网关。而网关的这个IP地址，是真实存在的，是可以访问百度的。
为了让 A 可以访问百度，那么我们可以采取这样的方法：让网关去帮助 A 访问，然后百度把结果传递给网关，而网关再把结果传递给 A，这样不就可以解决了？

不过电脑A, B, C都可能拜托网关去帮忙访问百度，而百度返回的结果 的目的IP都是网关的IP=192.168.1.1。那么网关该如何进行区分这结果是A的，B的还是C的呢？
我们去访问百度的时候，不是需要指定一个端口吗？只要我们把 A的IP + 端口 映射成 网关的IP+端口，不就可以唯一确定身份了？
例如A用端口60去访问百度，网关把  A的IP+端口60   映射成   网关的IP+端口80 不就可以了？

百度把结果返回给网关的80端口之后，网关再通过映射表，就可以把结果返回给 A的60端口 了。
如果B也是用60端口去访问百度的话，也是一样，可以把它映射到90端口。

这种方法地址的映射转换，我们也称之为网络地址转换。英文为 Network Address Translation，简称NAT。
而像A, B, C这样的IP地址我们也称之为内网IP，即私有IP；而像网关，百度这样的IP我们称之为外网IP，即全球IP。现在知道外网IP和内网IP了吧？
几点需要注意的地方
1、对于全球IP，显然每个IP都是唯一的，而对于私有IP，同一个局域网内，也得是唯一的，但在两个不同的局域网中，是可以有相同的私有IP的。
2、局域网内主机之间的通信，是不需要进行地址转换的，而如果需要访问外网，才需要进行地址转换。
实际上，我们也可以把这种地址转换称之为一种代理。网关就相当于一个代理，把局域网内的主机的一些信息都给隐藏了起来。百度并不知道是主机A访问它，他只知道是网关访问了它。
计算机网络",
Keep-Alive 和非 Keep-Alive 有什么区别？,"在早期的 HTTP/1.0 中，浏览器每次 发起 HTTP 请求都要与服务器创建一个新的 TCP 连接，服务器完成请求处理后立即断开 TCP 连接，服务器不跟踪每个客户也不记录过去的请求。
然而创建和关闭连接的过程需要消耗资源和时间，为了减少资源消耗，缩短响应时间，就需要重用连接。在 HTTP/1.1 版本中默认使用持久连接，在此之前的 HTTP 版本的默认连接都是使用非持久连接，如果想要在旧版本的 HTTP 协议上维持持久连接，则需要指定 connection 的首部字段的值为 Keep-Alive 来告诉对方这个请求响应完成后不要关闭，下一次咱们还用这个请求继续交流，我们用一个示意图来更加生动的表示两者的区别：

对于非 Keep=Alive 来说，必须为每一个请求的对象建立和维护一个全新的连接。对于每一个这样的连接，客户机和服务器都要分配 TCP 的缓冲区和变量，这给服务器带来的严重的负担，因为一台 Web 服务器可能同时服务于数以百计的客户机请求。在 Keep-Alive 方式下，服务器在响应后保持该 TCP 连接打开，在同一个客户机与服务器之间的后续请求和响应报文可通过相同的连接进行传送。甚至位于同一台服务器的多个 Web 页面在从该服务器发送给同一个客户机时，可以在单个持久 TCP 连接上进行。
然而，Keep-Alive 并不是没有缺点的，当长时间的保持 TCP 连接时容易导致系统资源被无效占用，若对 Keep-Alive 模式配置不当，将有可能比非 Keep-Alive 模式带来的损失更大。因此，我们需要正确地设置 keep-alive timeout 参数，当 TCP 连接在传送完最后一个 HTTP 响应，该连接会保持 keepalive_timeout 秒，之后就开始关闭这个链接。
计算机网络",
HTTP 长连接短连接使用场景是什么,"长连接多用于操作频繁，点对点的通讯，而且连接数不能太多情况。每个 TCP 连接都需要三步握手，这需要时间，如果每个操作都是先连接，再操作的话那么处理速度会降低很多， 所以每个操作完后都不断开，下次处理时直接发送数据包就 OK 了，不用建立 TCP 连接。例如： 数据库的连接用长连接， 如果用短连接频繁的通信会造成 socket 错误，而且频繁的 socket创建也是对资源的浪费。
而像 WEB 网站的 http 服务一般都用短链接，因为长连接对于服务端来说会耗费一定的 资源，而像 WEB 网站这么频繁的成千上万甚至上亿客户端的连接用短连接会更省一些资源， 如果用长连接，而且同时有成千上万的用户，如果每个用户都占用一个连接的话，那可想而知吧。所以并发量大，但每个用户无需频繁操作情况下需用短连接。
计算机网络",
DNS 为什么用 UDP,"其实 DNS 的整个过程是既使用 TCP 又使用 UDP。
当进行区域传送（主域名服务器向辅助域名服务器传送变化的那部分数据）时会使用 TCP，因为数据同步传送的数据量比一个请求和应答的数据量要多，而 TCP 允许的报文长度更长，因此为了保证数据的正确性，会使用基于可靠连接的 TCP。
当客户端向 DNS 服务器查询域名 ( 域名解析) 的时候，一般返回的内容不会超过 UDP 报文的最大长度，即 512 字节。用 UDP 传输时，不需要经过 TCP 三次握手的过程，从而大大提高了响应速度，但这要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性。
另外，关于 DNS 详细讲解的文章也可以看这篇：什么是 DNS？
什么是 DNS？
计算机网络",
简单说下怎么实现 DNS 劫持,"DNS 劫持即域名劫持，是通过将原域名对应的 IP 地址进行替换从而使得用户访问到错误的网站或者使得用户无法正常访问网站的一种攻击方式。域名劫持往往只能在特定的网络范围内进行，范围外的 DNS 服务器能够返回正常的 IP 地址。攻击者可以冒充原域名所属机构，通过电子邮件的方式修改组织机构的域名注册信息，或者将域名转让给其它组织，并将新的域名信息保存在所指定的 DNS 服务器中，从而使得用户无法通过对原域名进行解析来访问目的网址。
具体实施步骤如下：
① 获取要劫持的域名信息：攻击者首先会访问域名查询站点查询要劫持的域名信息。
② 控制域名相应的 E-MAIL 账号：在获取到域名信息后，攻击者通过暴力破解或者专门的方法破解公司注册域名时使用的 E-mail 账号所对应的密码。更高级的攻击者甚至能够直接对 E-mail 进行信息窃取。
③ 修改注册信息：当攻击者破解了 E-MAIL 后，会利用相关的更改功能修改该域名的注册信息，包括域名拥有者信息，DNS 服务器信息等。
④ 使用 E-MAIL 收发确认函：在修改完注册信息后，攻击者在 E-mail 真正拥有者之前收到修改域名注册信息的相关确认信息，并回复确认修改文件，待网络公司恢复已成功修改信件后，攻击者便成功完成 DNS 劫持。
用户端的一些预防手段：
直接通过 IP 地址访问网站，避开 DNS 劫持。
由于域名劫持往往只能在特定的网络范围内进行，因此一些高级用户可以通过网络设置让 DNS 指向正常的域名服务器以实现对目的网址的正常访问，例如将计算机首选 DNS 服务器的地址固定为 8.8.8.8。
计算机网络",
URI和 URL之间的区别,"URL，即统一资源定位符 (Uniform Resource Locator )，URL 其实就是我们平时上网时输入的网址，它标识一个互联网资源，并指定对其进行操作或获取该资源的方法。例如 https://leetcode-cn.com/problemset/all/ 这个 URL，标识一个特定资源并表示该资源的某种形式是可以通过 HTTP 协议从相应位置获得。
而 URI 则是统一资源标识符，URL 是 URI 的一个子集，两者都定义了资源是什么，而 URL 还定义了如何能访问到该资源。URI 是一种语义上的抽象概念，可以是绝对的，也可以是相对的，而URL则必须提供足够的信息来定位，是绝对的。简单地说，只要能唯一标识资源的就是 URI，在 URI 的基础上给出其资源的访问方式的就是 URL。
计算机网络",
TIME_WAIT 状态会导致什么问题，怎么解决,"我们考虑高并发短连接的业务场景，在高并发短连接的 TCP 服务器上，当服务器处理完请求后主动请求关闭连接，这样服务器上会有大量的连接处于 TIME_WAIT 状态，服务器维护每一个连接需要一个 socket，也就是每个连接会占用一个文件描述符，而文件描述符的使用是有上限的，如果持续高并发，会导致一些正常的 连接失败。
解决方案：修改配置或设置 SO_REUSEADDR 套接字，使得服务器处于 TIME-WAIT 状态下的端口能够快速回收和重用。
下面是读者提供的具体操作
修改配置文件：/etc/sysctl.conf
net.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；
net.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭
计算机网络",
有很多 TIME-WAIT 状态如何解决,"服务器可以设置 SO_REUSEADDR 套接字选项来通知内核，如果端口被占用，但 TCP 连接位于 TIME_WAIT 状态时可以重用端口。如果你的服务器程序停止后想立即重启，而新的套接字依旧希望使用同一端口，此时 SO_REUSEADDR 选项就可以避免 TIME-WAIT 状态。
也可以采用长连接的方式减少 TCP 的连接与断开，在长连接的业务中往往不需要考虑 TIME-WAIT 状态，但其实在长连接的业务中并发量一般不会太高。
计算机网络",
简单说下 SYN FLOOD 是什么,"SYN Flood 又称 SYN 洪水攻击，也是拒绝服务攻击的一种，是一种曾经很经典的攻击方式。攻击者利用TCP协议的安全缺陷，不断发送一系列的SYN请求到目标系统，消耗服务器系统的资源，从而导致目标服务器不响应合法流量请求。
在谈SYN flood 之前，我们先了解一下一次正常的网络请求都有哪些步骤，从而更清晰的了解SYN Flood的攻击方式。
一般一次正常的网络请求分以下几个步骤：
而此种攻击正是发生在TCP握手的阶段。TCP握手一般分为三步。客户端发送SYN请求数据包。服务器回复（ACK）确认包。客户端再次回复（ACK）确认包。至此，TCP握手阶段结束。

SYN Flood / SYN 洪水攻击原理
为了创建拒绝服务，攻击者利用的正是TCP协议的安全缺陷。在接收到初始SYN数据包之后，服务器用一个或多个SYN / ACK数据包进行响应，并等待握手中的最后一步。这是它的工作原理。
此种攻击是攻击者向目标服务器发送大量的SYN数据包，服务器会响应每一个请求然后返回ACK确认包，并且等待客户端的最终响应。
因为攻击者通常会采用虚拟ip，所以也就意味着服务器永远不可能接收到最终的确认包。这种情况下当服务器未接收到最终ACK数据包的时候，服务端一般会重试（再次发送SYN+ACK给客户端）并等待一段时间后丢弃这个未完成的连接。
这段时间的长度我们称为SYN Timeout，一般来说这个时间是分钟的数量级（大约为30秒-2分钟）；一个用户出现异常导致服务器的一个线程等待1分钟并不是什么很大的问题，但如果有一个恶意的攻击者大量模拟这种情况（伪造IP地址），那么服务器端将为了维护一个非常大的半连接列表而消耗非常多的资源。从而造成服务器的崩溃，即使你的服务器系统资源够强大，服务端也将忙于处理攻击者伪造的TCP连接请求而无暇理睬客户的正常请求（毕竟客户端的正常请求比率非常之小）。
此时，正常用户就会觉得服务器失去响应，这种情况就叫做，服务端收到了SYN Flood攻击（SYN 洪水攻击）。

在网络中，当服务器断开连接但连接另一端的客户端没有断开连接时，连接被认为是半开的。在这种类型的DDoS攻击中，目标服务器不断离开打开的连接，等待每个连接超时，然后端口再次可用。所以这种攻击也可以被认为是“半开攻击”。
计算机网络",
TCP 最大连接数限制,"如何标识一个TCP连接
在确定最大连接数之前，先来看看系统如何标识一个tcp连接。系统用一个4四元组来唯一标识一个TCP连接：{local ip, local port,remote ip,remote port}。
client最大tcp连接数
client每次发起tcp连接请求时，除非绑定端口，通常会让系统选取一个空闲的本地端口（local port），该端口是独占的，不能和其他tcp连接共享。tcp端口的数据类型是unsigned short，因此本地端口个数最大只有65536，端口0有特殊含义，不能使用，这样可用端口最多只有65535，所以在全部作为client端的情况下，最大tcp连接数为65535，这些连接可以连到不同的server ip。
server最大tcp连接数
server通常固定在某个本地端口上监听，等待client的连接请求。不考虑地址重用（unix的SO_REUSEADDR选项）的情况下，即使server端有多个ip，本地监听端口也是独占的，因此server端tcp连接4元组中只有remote ip（也就是client ip）和remote port（客户端port）是可变的，因此最大tcp连接为客户端ip数×客户端port数，对IPV4，不考虑ip地址分类等因素，最大tcp连接数约为2的32次方（ip数）×2的16次方（port数），也就是server端单机最大tcp连接数约为2的48次方。
实际的tcp连接数
上面给出的是理论上的单机最大连接数，在实际环境中，受到机器资源、操作系统等的限制，特别是sever端，其最大并发tcp连接数远不能达到理论上限。在unix/linux下限制连接数的主要因素是内存和允许的文件描述符个数（每个tcp连接都要占用一定内存，每个socket就是一个文件描述符），另外1024以下的端口通常为保留端口。在默认2.6内核配置下，经过试验，每个socket占用内存在15~20k之间。
影响一个socket占用内存的参数包括：
rmem_max
wmem_max
tcp_rmem
tcp_wmem
tcp_mem
grep skbuff /proc/slabinfo
对server端，通过增加内存、修改最大文件描述符个数等参数，单机最大并发TCP连接数超过10万 是没问题的，国外 Urban Airship 公司在产品环境中已做到 50 万并发 。在实际应用中，对大规模网络应用，还需要考虑C10K 问题。
摘自：https://blog.csdn.net/huangjin0507/article/details/52399957
计算机网络",
IP地址和MAC地址有什么区别？各自的用处？,"简单着说，IP 地址主要用来网络寻址用的，就是大致定位你在哪里，而 MAC 地址，则是身份的唯一象征，通过 MAC 来唯一确认这人是不是就是你，MAC 地址不具备寻址的功能。
具体可以看我这篇文章：互联网协议入门  看完你将豁然开朗。
互联网协议入门
计算机网络",
IPV4 地址不够如何解决,"目前主要有以下两种方式：
1、其实我们平时上网，电脑的 IP 地址都是属于私有地址，我无法出网关，我们的数据都是通过网关来中转的，这个其实 NAT 协议，可以用来暂缓 IPV4 地址不够，关于 NAT，具体可以看我写的这篇文章：什么是 NAT 网络地址转换协议？
什么是 NAT 网络地址转换协议？
2、IPv6 ：作为接替 IPv4 的下一代互联网协议，其可以实现 2 的 128 次方个地址，而这个数量级，即使是给地球上每一颗沙子都分配一个IP地址，该协议能够从根本上解决 IPv4 地址不够用的问题。
计算机网络",
如何区分LAN，WAN，WLAN ，VLAN 和VPN？,"在网络组建中，我们常常会遇见LAN，WAN，WLAN等名次，它们是怎么区别的呢？
一高科技公司，在上海北京两座城市都有办公室，北京、上海办公室内部网络就是局域网LAN。
局域网可以让一座办公楼、或几座办公楼的员工可以互相访问、或者访问局域网内部的服务器。
上文说了，几座办公楼用网线、或光纤连在一起就是局域网，那这个距离有没有限制？
北京的A栋办公楼，与B栋办公楼相隔1KM，用光纤连在一起，算局域网吗？
算！
如果距离比较远，比如10KM以上的连接，还是局域网吗？
通常这种长距离连接，称之为广域网WAN。
那1-10KM之间的连接，是局域网还是广域网？
都可以，这些名词的定义本身就不是那么严格，仅仅用来描述相对的短距离（LAN）与相对的长距离(WAN)。
北京的办公室与上海的办公室连接，这毫无疑问是广域网WAN，因为传输距离要超过1000KM。
无线局域网WLAN
最早的计算机之间的连接，仅仅有网线连接，大约十几年前，无线技术被应用在局域网里。通常这种无线信号的覆盖范围在100米以内，为了区别于网线连接的局域网LAN，称这种无线局域网技术为WLAN（Wireless Local Area Network）。
如果一个局域网既有有线连接，又有无线连接，这个局域网叫LAN还是WLAN？
还是叫局域网LAN，从某种意义上来说，局域网是一个统称，局域网包含两个部分：
有线局域网 Wired Local Area Network
无线局域网 Wireless Local Area Network
在没有VLAN技术之前，所有连接在同一台交换机的主机工作在一个广播域。但是往往这些主机并不在一个网段，而不同网段的主机不需要广播通信。
交换机的工作机制决定了，一定会将不同网段的广播消息扩散到连在交换机上每一台主机，无论接收的主机是否需要，这是一种类似性骚扰的不良行为，需要予以坚决避免！
于是业界发明了VLAN技术，在交换机上将相同的网段的主机放在一个VLAN，一个VLAN对应一个广播域。
自从有了VLAN技术，主机们只会接收属于自己VLAN的广播消息，而不会再接收别的VLAN（网段）的广播消息。从此，骚扰信息就大大减少！
上文说了，北京的办公室与上海的办公室的连接，是通过专线连接，这种专线称之为广域网专线。
这种广域网专线与互联网Internet是隔离的，“井水不犯河水”，既然是隔离的，可以避免在不安全的Internet上传输，所以数据的安全可以得到一定的保证。
但这种专线比较昂贵，通常20-50M包月，要好几万一个月，很多中小公司支付不起。
但是北京与上海的办公室还是需要通信的，那如何找到一个性价比高的解决方案呢？
既然上海、北京办公室的网关连接在互联网上，那么上海与北京之间的数据通信在互联网上传输，不是非常便利吗？
是的。
但是互联网是开放的，不安全的，由于很多通信软件本身不对数据加密，所以用户的明文数据就会暴露在互联网上，这样就存在数据泄露的风险！
如果用户数据在离开公司网关之前，被加密传输，然后进入互联网，那么数据的安全就可以得到保证。
到达另外一座城市的网关入口，再将加密数据解密成明文格式。
对于用户来说，这种加密/解密的过程，是透明的，用户感受不到它们的存在。
那么上海、北京网关之间加密/解密的方式，称之为虚拟私有网络VPN（Virtual Private Network）。
意思是，尽管互联网是开放的、共享的，但是可以借助加密/解密技术，让互联网成为公司的私有网络，仿佛互联网是公司独有的。也可以理解为一种私有专线，但相比物理专线，价格要便宜一个数量级。",
